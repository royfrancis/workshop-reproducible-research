[
  {
    "objectID": "pages/take-down.html",
    "href": "pages/take-down.html",
    "title": "Take-down",
    "section": "",
    "text": "There might be a lot of files stored on your computer after you’ve taken the course, depending on how many modules you’ve gone through. Here are instructions for how to remove them.\nAll the tutorials depend on you cloning the workshop-reproducible-research GitHub repo. This can be removed like any other directory; via Finder, Explorer or rm -rf workshop-reproducible-research. Note that this will also delete hidden directories such as .git, which contains the history of the repo."
  },
  {
    "objectID": "pages/take-down.html#conda",
    "href": "pages/take-down.html#conda",
    "title": "Take-down",
    "section": "1 Conda",
    "text": "1 Conda\nSeveral of the tutorials use Conda for installing packages. This amounts to about 2.6 GB if you’ve done all the tutorials. If you plan on using Conda in the future you can remove just the packages, or you can remove everything including Conda itself.\nIn order to remove all your environments, you first need to list them:\nconda env list\nFor each of the environments except “base” run the following:\nconda remove -n &lt;envname&gt; --all\nAnd, finally:\nconda clean --all\nIf you also want to remove Conda itself (i.e. removing all traces of Conda), you should first reverse the installation, this part should be run with conda:\nconda init --reverse\nNow find the path where Conda is installed. Look for the row “base environment”:\nconda info | grep \"base environment\"\nThis should say something like:\nbase environment : /Users/&lt;user&gt;/condaforge  (writable).\nThen remove the entire Miniforge directory:\nrm -rf /Users/&lt;user&gt;/miniforge3"
  },
  {
    "objectID": "pages/take-down.html#snakemake",
    "href": "pages/take-down.html#snakemake",
    "title": "Take-down",
    "section": "2 Snakemake",
    "text": "2 Snakemake\nSnakemake is installed via Conda and will be removed if you follow the instructions in the Conda section above. Note that Snakemake also generates a hidden .snakemake directory in the directory where it’s run. You can remove this with the following:\nrm -rf workshop-reproducible-research/tutorials/snakemake/.snakemake"
  },
  {
    "objectID": "pages/take-down.html#nextflow",
    "href": "pages/take-down.html#nextflow",
    "title": "Take-down",
    "section": "3 Nextflow",
    "text": "3 Nextflow\nSince we installed Nextflow using Conda we can remove it in the same way as above. You may also want to remove the results/ and work/ directories, which you can do like so:\nrm -rf workshop-reproducible-research/tutorials/nextflow/results\nrm -rf workshop-reproducible-research/tutorials/nextflow/work"
  },
  {
    "objectID": "pages/take-down.html#jupyter",
    "href": "pages/take-down.html#jupyter",
    "title": "Take-down",
    "section": "4 Jupyter",
    "text": "4 Jupyter\nJupyter is installed via Conda and will be removed if you follow the instructions in the Conda section above."
  },
  {
    "objectID": "pages/take-down.html#docker",
    "href": "pages/take-down.html#docker",
    "title": "Take-down",
    "section": "5 Docker",
    "text": "5 Docker\nDocker is infamous for quickly taking up huge amounts of space, and some maintenance is necessary every now and then. Here is how to uninstall Docker completely. Let’s start by removing individual images and containers:\n# Remove unused images\ndocker image prune\n\n# Remove stopped containers\ndocker container prune\n\n# Remove unused volumes (not used here, but included for reference)\ndocker volume prune\n\n# Stop and remove ALL containers\ndocker container rm $(docker container ls -a -q)\n\n# Remove ALL images\ndocker image rm $(docker image ls -a -q)\nRemoving Docker itself works differently on the three operating systems, which is described below:\n\n5.1 MacOS\nClick the Docker icon in the menu bar (upper right part of the screen) and select “Preferences”. In the upper right corner, you should find a little bug icon. Click on that icon and select “Reset to factory defaults”. You may have to fill in your password. Then select “Uninstall”. Once it’s done uninstalling, drag the Docker app from Applications to Trash.\n\n\n5.2 Linux\nIf you’ve installed Docker with apt-get, uninstall it like this:\napt-get purge docker-ce\nImages, containers, and volumes are not automatically removed. To delete all of them:\nrm -rf /var/lib/docker\n\n\n5.3 Windows\nUninstall Docker for Windows (on Windows 10) or Docker Toolbox (on Windows 7) via Control Panel &gt; Programs &gt; Programs and Features. Docker Toolbox will also have installed Oracle VM VirtualBox, so uninstall that as well if you’re not using it for other purposes."
  },
  {
    "objectID": "pages/introduction.html",
    "href": "pages/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to the tutorials! Here we will learn how to make a computational research project reproducible using several different tools, described in the figure below:\nThe figure above gives an overview of the different parts of computational reproducibility (data, code, workflow and environment), as well as the various tools that are used for each part; Git is, arguably, integral to all of the parts, but we only listed it in the code section for a less cluttered figure.\nThe course has a tutorial for each of the tools, all made so that they can be completed independently of each other. It is therefore perfectly possible to go through them in whatever order you prefer, but we suggest the following order:\nYou will find the tutorials in the Modules section in the navigation menu.\nPlease make sure to carefully follow the pre-course setup to install the tools and download the course material before starting with any of the tutorials. These will create quite a lot of files on your computer, some of which will actually take up a bit of storage space too. In order to remove any traces of these after completing the tutorials, please refer to the Take down section.\nBefore going into the tutorials themselves, we first describe the case study from which the example data comes from."
  },
  {
    "objectID": "pages/introduction.html#the-case-study",
    "href": "pages/introduction.html#the-case-study",
    "title": "Introduction",
    "section": "The case study",
    "text": "The case study\nWe will be running a small bioinformatics project as a case study, and use that to exemplify the different steps of setting up a reproducible research project. To give you some context, the study background and analysis steps are briefly described below.\n\nBackground\nThe data is taken from Osmundson, Dewell, and Darst (2013), who have studied methicillin-resistant Staphylococcus aureus (MRSA). MRSA is resistant to broad spectrum beta-lactam antibiotics and lead to difficult-to-treat infections in humans. Lytic bacteriophages have been suggested as potential therapeutic agents, or as the source of novel antibiotic proteins or peptides. One such protein, gp67, was identified as a transcription-inhibiting transcription factor with an antimicrobial effect. To identify S. aureus genes repressed by gp67, the authors expressed gp67 in S. aureus cells. RNA-seq was then performed on three S. aureus strains:\n\nRN4220 with pRMC2 with gp67\nRN4220 with empty pRMC2\nNCTC8325-4\n\n\n\nAnalysis\nThe graph below shows the different steps of the analysis that are included in this project:\n\nThe input files are:\n\nRNA-seq raw data (FASTQ files) for the three strains\nS. aureus genome sequence (a FASTA file)\nS. aureus genome annotation (a GFF file)\n\nThe workflow itself will perform the following tasks:\n\nDownloading and indexing of the reference genome using Bowtie2\nDownloading the raw FASTQ data from the Sequence Read Archive (SRA)\nRun some quality controls on the data using FastQC and MultiQC\nAlign the raw data to the genome and calculate the gene expression using featureCounts\nProduce supplementary materials using data from quality controls, gene expression and the workflow figure shown above"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#why-do-we-need-workflow-managers",
    "href": "lectures/snakemake/snakemake.html#why-do-we-need-workflow-managers",
    "title": "Making reproducible workflows with ",
    "section": "Why do we need workflow managers?",
    "text": "Why do we need workflow managers?\n\nAs projects grow or age, it becomes increasingly difficult to keep track of all the parts and how they fit together.\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=0];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n        0[label = \"fastqc\", color = \"0.39 0.6 0.85\", style=\"rounded\"];\n        1[label = \"get_SRA_by_accession\\nsample_id: SRR935090\", color = \"0.11 0.6 0.85\", style=\"rounded\"];\n        1 -&gt; 0\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n\nfastqc\n\n\n\n1\n\nget_SRA_by_accession\nsample_id: SRR935090\n\n\n\n1-&gt;0"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#why-do-we-need-workflow-managers-1",
    "href": "lectures/snakemake/snakemake.html#why-do-we-need-workflow-managers-1",
    "title": "Making reproducible workflows with ",
    "section": "Why do we need workflow managers?",
    "text": "Why do we need workflow managers?\n\nAs projects grow or age, it becomes increasingly difficult to keep track of all the parts and how they fit together.\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=0];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n        0[label = \"fastqc\", color = \"0.39 0.6 0.85\", style=\"rounded\"];\n        1[label = \"get_SRA_by_accession\\nsample_id: SRR935090\", color = \"0.61 0.6 0.85\", style=\"rounded\"];\n        2[label = \"fastqc\", color = \"0.39 0.6 0.85\", style=\"rounded\"];\n        3[label = \"get_SRA_by_accession\\nsample_id: SRR935091\", color = \"0.61 0.6 0.85\", style=\"rounded\"];\n        4[label = \"fastqc\", color = \"0.39 0.6 0.85\", style=\"rounded\"];\n        5[label = \"get_SRA_by_accession\\nsample_id: SRR935092\", color = \"0.61 0.6 0.85\", style=\"rounded\"];\n        1 -&gt; 0\n        3 -&gt; 2\n        5 -&gt; 4\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n\nfastqc\n\n\n\n1\n\nget_SRA_by_accession\nsample_id: SRR935090\n\n\n\n1-&gt;0\n\n\n\n\n\n2\n\nfastqc\n\n\n\n3\n\nget_SRA_by_accession\nsample_id: SRR935091\n\n\n\n3-&gt;2\n\n\n\n\n\n4\n\nfastqc\n\n\n\n5\n\nget_SRA_by_accession\nsample_id: SRR935092\n\n\n\n5-&gt;4"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#why-do-we-need-workflow-managers-2",
    "href": "lectures/snakemake/snakemake.html#why-do-we-need-workflow-managers-2",
    "title": "Making reproducible workflows with ",
    "section": "Why do we need workflow managers?",
    "text": "Why do we need workflow managers?\n\nAs projects grow or age, it becomes increasingly difficult to keep track of all the parts and how they fit together.\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=0];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n        0[label = \"align_to_genome\", color = \"0.06 0.6 0.85\", style=\"rounded\"];\n        1[label = \"get_SRA_by_accession\\nsample_id: SRR935091\", color = \"0.00 0.6 0.85\", style=\"rounded\"];\n        2[label = \"index_genome\", color = \"0.61 0.6 0.85\", style=\"rounded\"];\n        3[label = \"get_genome_fasta\\ngenome_id: NCTC8325\", color = \"0.33 0.6 0.85\", style=\"rounded\"];\n        4[label = \"align_to_genome\", color = \"0.06 0.6 0.85\", style=\"rounded\"];\n        5[label = \"get_SRA_by_accession\\nsample_id: SRR935092\", color = \"0.00 0.6 0.85\", style=\"rounded\"];\n        6[label = \"align_to_genome\", color = \"0.06 0.6 0.85\", style=\"rounded\"];\n        7[label = \"get_SRA_by_accession\\nsample_id: SRR935090\", color = \"0.00 0.6 0.85\", style=\"rounded\"];\n        1 -&gt; 0\n        2 -&gt; 0\n        3 -&gt; 2\n        5 -&gt; 4\n        2 -&gt; 4\n        7 -&gt; 6\n        2 -&gt; 6\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n\nalign_to_genome\n\n\n\n1\n\nget_SRA_by_accession\nsample_id: SRR935091\n\n\n\n1-&gt;0\n\n\n\n\n\n2\n\nindex_genome\n\n\n\n2-&gt;0\n\n\n\n\n\n4\n\nalign_to_genome\n\n\n\n2-&gt;4\n\n\n\n\n\n6\n\nalign_to_genome\n\n\n\n2-&gt;6\n\n\n\n\n\n3\n\nget_genome_fasta\ngenome_id: NCTC8325\n\n\n\n3-&gt;2\n\n\n\n\n\n5\n\nget_SRA_by_accession\nsample_id: SRR935092\n\n\n\n5-&gt;4\n\n\n\n\n\n7\n\nget_SRA_by_accession\nsample_id: SRR935090\n\n\n\n7-&gt;6"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#why-do-we-need-workflow-managers-3",
    "href": "lectures/snakemake/snakemake.html#why-do-we-need-workflow-managers-3",
    "title": "Making reproducible workflows with ",
    "section": "Why do we need workflow managers?",
    "text": "Why do we need workflow managers?\n\nA workflow manager helps you scale up both in complexity and dataset size\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=0];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n        0[label = \"all\", color = \"0.06 0.6 0.85\", style=\"rounded\"];\n        1[label = \"generate_count_table\", color = \"0.50 0.6 0.85\", style=\"rounded\"];\n        2[label = \"sort_bam\\nprefix: results/bam/SRR935090\", color = \"0.17 0.6 0.85\", style=\"rounded\"];\n        3[label = \"align_to_genome\", color = \"0.61 0.6 0.85\", style=\"rounded\"];\n        4[label = \"get_SRA_by_accession\\nsample_id: SRR935090\", color = \"0.22 0.6 0.85\", style=\"rounded\"];\n        5[label = \"index_genome\", color = \"0.56 0.6 0.85\", style=\"rounded\"];\n        6[label = \"get_genome_fasta\\ngenome_id: NCTC8325\", color = \"0.28 0.6 0.85\", style=\"rounded\"];\n        7[label = \"sort_bam\\nprefix: results/bam/SRR935091\", color = \"0.17 0.6 0.85\", style=\"rounded\"];\n        8[label = \"align_to_genome\", color = \"0.61 0.6 0.85\", style=\"rounded\"];\n        9[label = \"get_SRA_by_accession\\nsample_id: SRR935091\", color = \"0.22 0.6 0.85\", style=\"rounded\"];\n        10[label = \"sort_bam\\nprefix: results/bam/SRR935092\", color = \"0.17 0.6 0.85\", style=\"rounded\"];\n        11[label = \"align_to_genome\", color = \"0.61 0.6 0.85\", style=\"rounded\"];\n        12[label = \"get_SRA_by_accession\\nsample_id: SRR935092\", color = \"0.22 0.6 0.85\", style=\"rounded\"];\n        13[label = \"get_genome_gff3\\ngenome_id: NCTC8325\", color = \"0.44 0.6 0.85\", style=\"rounded\"];\n        14[label = \"multiqc\", color = \"0.11 0.6 0.85\", style=\"rounded\"];\n        15[label = \"fastqc\", color = \"0.00 0.6 0.85\", style=\"rounded\"];\n        16[label = \"fastqc\", color = \"0.00 0.6 0.85\", style=\"rounded\"];\n        17[label = \"fastqc\", color = \"0.00 0.6 0.85\", style=\"rounded\"];\n        18[label = \"generate_rulegraph\", color = \"0.33 0.6 0.85\", style=\"rounded\"];\n        19[label = \"make_supplementary\", color = \"0.39 0.6 0.85\", style=\"rounded\"];\n        1 -&gt; 0\n        14 -&gt; 0\n        18 -&gt; 0\n        19 -&gt; 0\n        2 -&gt; 1\n        7 -&gt; 1\n        10 -&gt; 1\n        13 -&gt; 1\n        3 -&gt; 2\n        4 -&gt; 3\n        5 -&gt; 3\n        6 -&gt; 5\n        8 -&gt; 7\n        9 -&gt; 8\n        5 -&gt; 8\n        11 -&gt; 10\n        12 -&gt; 11\n        5 -&gt; 11\n        15 -&gt; 14\n        16 -&gt; 14\n        17 -&gt; 14\n        4 -&gt; 15\n        9 -&gt; 16\n        12 -&gt; 17\n        1 -&gt; 19\n        14 -&gt; 19\n        18 -&gt; 19\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n\nall\n\n\n\n1\n\ngenerate_count_table\n\n\n\n1-&gt;0\n\n\n\n\n\n19\n\nmake_supplementary\n\n\n\n1-&gt;19\n\n\n\n\n\n2\n\nsort_bam\nprefix: results/bam/SRR935090\n\n\n\n2-&gt;1\n\n\n\n\n\n3\n\nalign_to_genome\n\n\n\n3-&gt;2\n\n\n\n\n\n4\n\nget_SRA_by_accession\nsample_id: SRR935090\n\n\n\n4-&gt;3\n\n\n\n\n\n15\n\nfastqc\n\n\n\n4-&gt;15\n\n\n\n\n\n5\n\nindex_genome\n\n\n\n5-&gt;3\n\n\n\n\n\n8\n\nalign_to_genome\n\n\n\n5-&gt;8\n\n\n\n\n\n11\n\nalign_to_genome\n\n\n\n5-&gt;11\n\n\n\n\n\n6\n\nget_genome_fasta\ngenome_id: NCTC8325\n\n\n\n6-&gt;5\n\n\n\n\n\n7\n\nsort_bam\nprefix: results/bam/SRR935091\n\n\n\n7-&gt;1\n\n\n\n\n\n8-&gt;7\n\n\n\n\n\n9\n\nget_SRA_by_accession\nsample_id: SRR935091\n\n\n\n9-&gt;8\n\n\n\n\n\n16\n\nfastqc\n\n\n\n9-&gt;16\n\n\n\n\n\n10\n\nsort_bam\nprefix: results/bam/SRR935092\n\n\n\n10-&gt;1\n\n\n\n\n\n11-&gt;10\n\n\n\n\n\n12\n\nget_SRA_by_accession\nsample_id: SRR935092\n\n\n\n12-&gt;11\n\n\n\n\n\n17\n\nfastqc\n\n\n\n12-&gt;17\n\n\n\n\n\n13\n\nget_genome_gff3\ngenome_id: NCTC8325\n\n\n\n13-&gt;1\n\n\n\n\n\n14\n\nmultiqc\n\n\n\n14-&gt;0\n\n\n\n\n\n14-&gt;19\n\n\n\n\n\n15-&gt;14\n\n\n\n\n\n16-&gt;14\n\n\n\n\n\n17-&gt;14\n\n\n\n\n\n18\n\ngenerate_rulegraph\n\n\n\n18-&gt;0\n\n\n\n\n\n18-&gt;19\n\n\n\n\n\n19-&gt;0"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#workflow-managers-for-bioinformatics",
    "href": "lectures/snakemake/snakemake.html#workflow-managers-for-bioinformatics",
    "title": "Making reproducible workflows with ",
    "section": "Workflow managers for bioinformatics",
    "text": "Workflow managers for bioinformatics\n\nMost common\n\nSnakemake\nNextflow\n\n\n\nOthers\n\nMakeflow\nBpipe\nPachyderm"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#snakemake-workflows",
    "href": "lectures/snakemake/snakemake.html#snakemake-workflows",
    "title": "Making reproducible workflows with ",
    "section": "Snakemake workflows",
    "text": "Snakemake workflows\n\n\nAutomatically track input/output file dependencies\nAre built from rules\nAre generalized with wildcards\nUse a Python-based definition language\nEasily scale from laptops to HPC clusters"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#reproducible",
    "href": "lectures/snakemake/snakemake.html#reproducible",
    "title": "Making reproducible workflows with ",
    "section": "Reproducible…",
    "text": "Reproducible…"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#and-scalable-workflows",
    "href": "lectures/snakemake/snakemake.html#and-scalable-workflows",
    "title": "Making reproducible workflows with ",
    "section": "…and scalable workflows",
    "text": "…and scalable workflows"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#example-sequence-trimming",
    "href": "lectures/snakemake/snakemake.html#example-sequence-trimming",
    "title": "Making reproducible workflows with ",
    "section": "Example: sequence trimming",
    "text": "Example: sequence trimming\nGoal: Create workflow to trim and compress FASTQ files\n./\n ├── a.fastq\n └── b.fastq"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#example-sequence-trimming-1",
    "href": "lectures/snakemake/snakemake.html#example-sequence-trimming-1",
    "title": "Making reproducible workflows with ",
    "section": "Example: sequence trimming",
    "text": "Example: sequence trimming\nUsing a bash-script:\nfor input in *.fastq\ndo\n   sample=$(echo ${input} | sed 's/.fastq//')\n   # 1. Trim fastq file (trim 5 bp from left, 10 bp from right)\n   seqtk trimfq -b 5 -e 10 $input &gt; ${sample}.trimmed.fastq\n   # 2. Compress fastq file\n   gzip -c ${sample}.trimmed.fastq &gt; ${sample}.trimmed.fastq.gz\n   # 3. Remove intermediate files\n   rm ${sample}.trimmed.fastq\ndone\n\nExecution:\n$ bash trimfastq.sh"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#example-sequence-trimming-2",
    "href": "lectures/snakemake/snakemake.html#example-sequence-trimming-2",
    "title": "Making reproducible workflows with ",
    "section": "Example: sequence trimming",
    "text": "Example: sequence trimming\nUsing Snakemake rules:\nrule trim_fastq:\n    output: temp(\"{sample}.trimmed.fastq\")\n    input: \"{sample}.fastq\"\n    shell:\n        \"seqtk trimfq -b 5 -e 10 {input} &gt; {output}\"\nrule gzip:\n    output: \"{sample}.trimmed.fastq.gz\"\n    input: \"{sample}.trimmed.fastq\"\n    shell:\n        \"gzip -c {input} &gt; {output}\"\n\nExecution:\n$ snakemake -c 1 a.trimmed.fastq.gz b.trimmed.fastq.gz"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section",
    "href": "lectures/snakemake/snakemake.html#section",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "$ snakemake -c 1 a.trimmed.fastq.gz b.trimmed.fastq.gz"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-1",
    "href": "lectures/snakemake/snakemake.html#section-1",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "$ snakemake -c 1 a.trimmed.fastq.gz b.trimmed.fastq.gz\nProvided cores: 1\nRules claiming more threads will be scaled down.\nJob counts:\ncount   jobs\n2       gzip\n2       trim_fastq\n4\nrule trim_fastq:\n    input: a.fastq\n    output: a.trimmed.fastq\n    wildcards: sample=a\n    1 of 4 steps (25%) done\n\nrule gzip:\n    input: a.trimmed.fastq\n    output: a.trimmed.fastq.gz\n    wildcards: sample=a\nRemoving temporary output file a.trimmed.fastq.\n2 of 4 steps (50%) done\n\nrule trim_fastq:\n    input: b.fastq\n    output: b.trimmed.fastq\n    wildcards: sample=b\n3 of 4 steps (75%) done\n\nrule gzip:\n    input: b.trimmed.fastq\n    output: b.trimmed.fastq.gz\n    wildcards: sample=b\nRemoving temporary output file b.trimmed.fastq.\n4 of 4 steps (100%) done"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#getting-into-the-snakemake-mindset",
    "href": "lectures/snakemake/snakemake.html#getting-into-the-snakemake-mindset",
    "title": "Making reproducible workflows with ",
    "section": "Getting into the Snakemake mindset",
    "text": "Getting into the Snakemake mindset\nFrom the Snakemake documentation:\n\n\n\n“A Snakemake workflow is defined by specifying rules in a Snakefile.”\n\n\n\n\n“Rules decompose the workflow into small steps.”\n\n\n\n\n“Snakemake automatically determines the dependencies between the rules by matching file names.”"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-2",
    "href": "lectures/snakemake/snakemake.html#section-2",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "By themselves, rules only define what files can be generated\n\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=0];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n0 [ shape=none, margin=0, label=&lt;&lt;table border=\"2\" color=\"#57D957\" cellspacing=\"3\" cellborder=\"0\"&gt;\n&lt;tr&gt;&lt;td&gt;\n&lt;b&gt;&lt;font point-size=\"18\"&gt;               gzip              &lt;/font&gt;&lt;/b&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"left\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;&#8618; input&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font face=\"monospace\"&gt;{sample}.trimmed.fastq&lt;/font&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"right\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;output &rarr;&lt;/font&gt;&lt;/b&gt; &lt;/td&gt; &lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font face=\"monospace\"&gt;{sample}.trimmed.fastq.gz&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;&gt;]\n1 [ shape=none, margin=0, label=&lt;&lt;table border=\"2\" color=\"#D95757\" cellspacing=\"3\" cellborder=\"0\"&gt;\n&lt;tr&gt;&lt;td&gt;\n&lt;b&gt;&lt;font point-size=\"18\"&gt;       trim_fastq       &lt;/font&gt;&lt;/b&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"left\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;&#8618; input&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font face=\"monospace\"&gt;{sample}.fastq&lt;/font&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"right\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;output &rarr;&lt;/font&gt;&lt;/b&gt; &lt;/td&gt; &lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font face=\"monospace\"&gt;{sample}.trimmed.fastq&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;&gt;]\n        1 -&gt; 0\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n               gzip              \n \n↪ input\n \n{sample}.trimmed.fastq\n \noutput →\n \n{sample}.trimmed.fastq.gz\n\n\n\n\n\n\n1\n       trim_fastq       \n \n↪ input\n \n{sample}.fastq\n \noutput →\n \n{sample}.trimmed.fastq\n\n\n\n\n\n\n1-&gt;0"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-3",
    "href": "lectures/snakemake/snakemake.html#section-3",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "By themselves, rules only define what files can be generated\nThe actual rules to run are determined automatically from the files you want, so called targets\n\n\n$ snakemake -c 1 a.trimmed.fastq.gz b.trimmed.fastq.gz\n\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=0];\n    node[shape=box, style=rounded, fontname=sans, fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n\n0 [ shape=none, margin=0, label=&lt;&lt;table border=\"2\" color=\"#57D957\" cellspacing=\"3\" cellborder=\"0\"&gt;\n&lt;tr&gt;&lt;td&gt;\n&lt;b&gt;&lt;font point-size=\"18\"&gt;        gzip       &lt;/font&gt;&lt;/b&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"left\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;&#8618; input&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;a.trimmed.fastq&lt;/font&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"right\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;output &rarr;&lt;/font&gt;&lt;/b&gt; &lt;/td&gt; &lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;a.trimmed.fastq.gz&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;&gt;]\n\n1 [ shape=none, margin=0, label=&lt;&lt;table border=\"2\" color=\"#D95757\" cellspacing=\"3\" cellborder=\"0\"&gt;\n&lt;tr&gt;&lt;td&gt;\n&lt;b&gt;&lt;font point-size=\"18\"&gt;trim_fastq&lt;/font&gt;&lt;/b&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"left\"&gt; &lt;b&gt;&lt;font point-size=\"10\"&gt;&#8618; input&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;a.fastq&lt;/font&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"right\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;output &rarr;&lt;/font&gt;&lt;/b&gt; &lt;/td&gt; &lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;a.trimmed.fastq&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;&gt;]\n\n\n2 [ shape=none, margin=0, label=&lt;&lt;table border=\"2\" color=\"#57D957\" cellspacing=\"3\" cellborder=\"0\"&gt;\n&lt;tr&gt;&lt;td&gt;\n&lt;b&gt;&lt;font point-size=\"18\"&gt;        gzip       &lt;/font&gt;&lt;/b&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"left\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;&#8618; input&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;b.trimmed.fastq&lt;/font&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"right\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;output &rarr;&lt;/font&gt;&lt;/b&gt; &lt;/td&gt; &lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;b.trimmed.fastq.gz&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;&gt;]\n\n3 [ shape=none, margin=0, label=&lt;&lt;table border=\"2\" color=\"#D95757\" cellspacing=\"3\" cellborder=\"0\"&gt;\n&lt;tr&gt;&lt;td&gt;\n&lt;b&gt;&lt;font point-size=\"18\"&gt;trim_fastq&lt;/font&gt;&lt;/b&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"left\"&gt; &lt;b&gt;&lt;font point-size=\"10\"&gt;&#8618; input&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;b.fastq&lt;/font&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"right\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;output &rarr;&lt;/font&gt;&lt;/b&gt; &lt;/td&gt; &lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;b.trimmed.fastq&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;&gt;]\n\n        1 -&gt; 0\n        3 -&gt; 2\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n        gzip       \n \n↪ input\n \na.trimmed.fastq\n \noutput →\n \na.trimmed.fastq.gz\n\n\n\n\n\n\n1\ntrim_fastq\n \n↪ input\n \na.fastq\n \noutput →\n \na.trimmed.fastq\n\n\n\n\n\n\n1-&gt;0\n\n\n\n\n\n2\n        gzip       \n \n↪ input\n \nb.trimmed.fastq\n \noutput →\n \nb.trimmed.fastq.gz\n\n\n\n\n\n\n3\ntrim_fastq\n \n↪ input\n \nb.fastq\n \noutput →\n \nb.trimmed.fastq\n\n\n\n\n\n\n3-&gt;2"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-4",
    "href": "lectures/snakemake/snakemake.html#section-4",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "By themselves, rules only define what files can be generated\nThe actual rules to run are determined automatically from the files you want, so-called targets\n\n\n$ snakemake -c 1 a.trimmed.fastq.gz\n\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=0];\n    node[shape=box, style=rounded, fontname=sans, fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n\n0 [ shape=none, margin=0, label=&lt;&lt;table border=\"2\" color=\"#57D957\" cellspacing=\"3\" cellborder=\"0\"&gt;\n&lt;tr&gt;&lt;td&gt;\n&lt;b&gt;&lt;font point-size=\"18\"&gt;        gzip       &lt;/font&gt;&lt;/b&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"left\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;&#8618; input&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;a.trimmed.fastq&lt;/font&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"right\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;output &rarr;&lt;/font&gt;&lt;/b&gt; &lt;/td&gt; &lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;a.trimmed.fastq.gz&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;&gt;]\n\n1 [ shape=none, margin=0, label=&lt;&lt;table border=\"2\" color=\"#D95757\" cellspacing=\"3\" cellborder=\"0\"&gt;\n&lt;tr&gt;&lt;td&gt;\n&lt;b&gt;&lt;font point-size=\"18\"&gt;trim_fastq&lt;/font&gt;&lt;/b&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"left\"&gt; &lt;b&gt;&lt;font point-size=\"10\"&gt;&#8618; input&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;a.fastq&lt;/font&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;hr/&gt;\n&lt;tr&gt;&lt;td align=\"right\"&gt; &lt;b&gt;&lt;font point-size=\"14\"&gt;output &rarr;&lt;/font&gt;&lt;/b&gt; &lt;/td&gt; &lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;font point-size=\"8\" face=\"monospace\"&gt;a.trimmed.fastq&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;&gt;]\n\n        1 -&gt; 0\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n        gzip       \n \n↪ input\n \na.trimmed.fastq\n \noutput →\n \na.trimmed.fastq.gz\n\n\n\n\n\n\n1\ntrim_fastq\n \n↪ input\n \na.fastq\n \noutput →\n \na.trimmed.fastq\n\n\n\n\n\n\n1-&gt;0"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-5",
    "href": "lectures/snakemake/snakemake.html#section-5",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "By themselves, rules only define what files can be generated\nThe actual rules to run are determined automatically from the files you want, so called targets\nIt can therefore be helpful to think of Snakemake workflows in a bottom-up manner, starting with the output\n\nrule trim_fastq:\n    output: temp(\"{sample}.trimmed.fastq\")\n    input: \"{sample}.fastq\"\n    shell:\n        \"seqtk trimfq -b 5 -e 10 {input} &gt; {output}\"\nrule gzip:\n    output: \"{sample}.trimmed.fastq.gz\"\n    input: \"{sample}.trimmed.fastq\"\n    shell:\n        \"gzip -c {input} &gt; {output}\""
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-6",
    "href": "lectures/snakemake/snakemake.html#section-6",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "By themselves, rules only define what files can be generated\nThe actual rules to run are determined automatically from the files you want, so called targets\nIt can therefore be helpful to think of Snakemake workflows in a bottom-up manner, starting with the output\nIf no target is passed at the command line, Snakemake will use the first defined rule in the Snakefile as a target\n\nrule all:\n    input:\n        \"a.trimmed.fastq.gz\",\n        \"b.trimmed.fastq.gz\"\nrule trim_fastq:\n    output: temp(\"{sample}.trimmed.fastq\")\n    input: \"{sample}.fastq\"\n    shell:\n        \"seqtk trimfq -b 5 -e 10 {input} &gt; {output}\"\n[...]"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#how-does-snakemake-keep-track-of-what-files-to-generate",
    "href": "lectures/snakemake/snakemake.html#how-does-snakemake-keep-track-of-what-files-to-generate",
    "title": "Making reproducible workflows with ",
    "section": "How does Snakemake keep track of what files to generate?",
    "text": "How does Snakemake keep track of what files to generate?\nExample from the practical tutorial"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-7",
    "href": "lectures/snakemake/snakemake.html#section-7",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "The tutorial contains a workflow to download and map RNA-seq reads against a reference genome.\n\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=1];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n        0[label = \"make_supplementary\", color = \"black\", style=\"rounded\"];\n        1[label = \"generate_count_table\", color = \"black\", style=\"rounded\"];\n        2[label = \"sort_bam\\nprefix: results/bam/SRR935090\", color = \"black\", style=\"rounded\"];\n        3[label = \"align_to_genome\", color = \"black\", style=\"rounded\"];\n        4[label = \"get_SRA_by_accession\\nsample_id: SRR935090\", color = \"black\", style=\"rounded\"];\n        5[label = \"index_genome\", color = \"black\", style=\"rounded\"];\n        6[label = \"get_genome_fasta\\ngenome_id: NCTC8325\", color = \"black\", style=\"rounded\"];\n        7[label = \"get_genome_gff3\\ngenome_id: NCTC8325\", color = \"black\", style=\"rounded\"];\n        8[label = \"multiqc\", color = \"black\", style=\"rounded\"];\n        9[label = \"fastqc\", color = \"black\", style=\"rounded\"];\n        10[label = \"generate_rulegraph\", color = \"black\", style=\"rounded\"];\n        1 -&gt; 0\n        8 -&gt; 0\n        10 -&gt; 0\n        2 -&gt; 1\n        7 -&gt; 1\n        3 -&gt; 2\n        4 -&gt; 3\n        5 -&gt; 3\n        6 -&gt; 5\n        9 -&gt; 8\n        4 -&gt; 9\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n\nmake_supplementary\n\n\n\n1\n\ngenerate_count_table\n\n\n\n1-&gt;0\n\n\n\n\n\n2\n\nsort_bam\nprefix: results/bam/SRR935090\n\n\n\n2-&gt;1\n\n\n\n\n\n3\n\nalign_to_genome\n\n\n\n3-&gt;2\n\n\n\n\n\n4\n\nget_SRA_by_accession\nsample_id: SRR935090\n\n\n\n4-&gt;3\n\n\n\n\n\n9\n\nfastqc\n\n\n\n4-&gt;9\n\n\n\n\n\n5\n\nindex_genome\n\n\n\n5-&gt;3\n\n\n\n\n\n6\n\nget_genome_fasta\ngenome_id: NCTC8325\n\n\n\n6-&gt;5\n\n\n\n\n\n7\n\nget_genome_gff3\ngenome_id: NCTC8325\n\n\n\n7-&gt;1\n\n\n\n\n\n8\n\nmultiqc\n\n\n\n8-&gt;0\n\n\n\n\n\n9-&gt;8\n\n\n\n\n\n10\n\ngenerate_rulegraph\n\n\n\n10-&gt;0"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-8",
    "href": "lectures/snakemake/snakemake.html#section-8",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "The tutorial contains a workflow to download and map RNA-seq reads against a reference genome.\nHere we ask for results/supplementary.html, which is an Quarto report generated by the rule make_supplementary:\n\n\n$ snakemake -c 1 results/supplementary.html\n\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=1];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n        0[label = \"make_supplementary\", color = \"red\", style=\"rounded\"];\n        1[label = \"generate_count_table\", color = \"black\", style=\"rounded\"];\n        2[label = \"sort_bam\\nprefix: results/bam/SRR935090\", color = \"black\", style=\"rounded\"];\n        3[label = \"align_to_genome\", color = \"black\", style=\"rounded\"];\n        4[label = \"get_SRA_by_accession\\nsample_id: SRR935090\", color = \"black\", style=\"rounded\"];\n        5[label = \"index_genome\", color = \"black\", style=\"rounded\"];\n        6[label = \"get_genome_fasta\\ngenome_id: NCTC8325\", color = \"black\", style=\"rounded\"];\n        7[label = \"get_genome_gff3\\ngenome_id: NCTC8325\", color = \"black\", style=\"rounded\"];\n        8[label = \"multiqc\", color = \"black\", style=\"rounded\"];\n        9[label = \"fastqc\", color = \"black\", style=\"rounded\"];\n        10[label = \"generate_rulegraph\", color = \"black\", style=\"rounded\"];\n        1 -&gt; 0\n        8 -&gt; 0\n        10 -&gt; 0\n        2 -&gt; 1\n        7 -&gt; 1\n        3 -&gt; 2\n        4 -&gt; 3\n        5 -&gt; 3\n        6 -&gt; 5\n        9 -&gt; 8\n        4 -&gt; 9\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n\nmake_supplementary\n\n\n\n1\n\ngenerate_count_table\n\n\n\n1-&gt;0\n\n\n\n\n\n2\n\nsort_bam\nprefix: results/bam/SRR935090\n\n\n\n2-&gt;1\n\n\n\n\n\n3\n\nalign_to_genome\n\n\n\n3-&gt;2\n\n\n\n\n\n4\n\nget_SRA_by_accession\nsample_id: SRR935090\n\n\n\n4-&gt;3\n\n\n\n\n\n9\n\nfastqc\n\n\n\n4-&gt;9\n\n\n\n\n\n5\n\nindex_genome\n\n\n\n5-&gt;3\n\n\n\n\n\n6\n\nget_genome_fasta\ngenome_id: NCTC8325\n\n\n\n6-&gt;5\n\n\n\n\n\n7\n\nget_genome_gff3\ngenome_id: NCTC8325\n\n\n\n7-&gt;1\n\n\n\n\n\n8\n\nmultiqc\n\n\n\n8-&gt;0\n\n\n\n\n\n9-&gt;8\n\n\n\n\n\n10\n\ngenerate_rulegraph\n\n\n\n10-&gt;0"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-9",
    "href": "lectures/snakemake/snakemake.html#section-9",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "The tutorial contains a workflow to download and map RNA-seq reads against a reference genome.\nHere we ask for results/supplementary.html, which is an Quarto report generated by the rule make_supplementary:\nIf the timestamp of a file upstream in the workflow is updated…\n\n\n$ touch results/bowtie2/NCTC8325.1.bt2\n\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=1];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n        0[label = \"make_supplementary\", color = \"black\", style=\"rounded\"];\n        1[label = \"generate_count_table\", color = \"black\", style=\"rounded\"];\n        2[label = \"sort_bam\\nprefix: results/bowtie2/SRR935090\", color = \"black\", style=\"rounded\"];\n        3[label = \"align_to_genome\", color = \"black\", style=\"rounded\"];\n        4[label = \"get_SRA_by_accession\\nsample_id: SRR935090\", color = \"black\", style=\"rounded\"];\n        5[label = \"index_genome*\", color = \"cyan\", style=\"rounded\"];\n        6[label = \"get_genome_fasta\\ngenome_id: NCTC8325\", color = \"black\", style=\"rounded\"];\n        7[label = \"get_genome_gff3\\ngenome_id: NCTC8325\", color = \"black\", style=\"rounded\"];\n        8[label = \"multiqc\", color = \"black\", style=\"rounded\"];\n        9[label = \"fastqc\", color = \"black\", style=\"rounded\"];\n        10[label = \"generate_rulegraph\", color = \"black\", style=\"rounded\"];\n        1 -&gt; 0\n        8 -&gt; 0\n        10 -&gt; 0\n        2 -&gt; 1\n        7 -&gt; 1\n        3 -&gt; 2\n        4 -&gt; 3\n        5 -&gt; 3\n        6 -&gt; 5\n        9 -&gt; 8\n        4 -&gt; 9\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n\nmake_supplementary\n\n\n\n1\n\ngenerate_count_table\n\n\n\n1-&gt;0\n\n\n\n\n\n2\n\nsort_bam\nprefix: results/bowtie2/SRR935090\n\n\n\n2-&gt;1\n\n\n\n\n\n3\n\nalign_to_genome\n\n\n\n3-&gt;2\n\n\n\n\n\n4\n\nget_SRA_by_accession\nsample_id: SRR935090\n\n\n\n4-&gt;3\n\n\n\n\n\n9\n\nfastqc\n\n\n\n4-&gt;9\n\n\n\n\n\n5\n\nindex_genome*\n\n\n\n5-&gt;3\n\n\n\n\n\n6\n\nget_genome_fasta\ngenome_id: NCTC8325\n\n\n\n6-&gt;5\n\n\n\n\n\n7\n\nget_genome_gff3\ngenome_id: NCTC8325\n\n\n\n7-&gt;1\n\n\n\n\n\n8\n\nmultiqc\n\n\n\n8-&gt;0\n\n\n\n\n\n9-&gt;8\n\n\n\n\n\n10\n\ngenerate_rulegraph\n\n\n\n10-&gt;0"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-10",
    "href": "lectures/snakemake/snakemake.html#section-10",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "The tutorial contains a workflow to download and map RNA-seq reads against a reference genome.\nHere we ask for results/supplementary.html, which is an Quarto report generated by the rule make_supplementary:\nIf the timestamp of a file upstream in the workflow is updated…\nSnakemake detects a file change and only reruns the necessary rules.\n\n\n$ snakemake -c 1 results/supplementary.html\n\n\n\ndigraph snakemake_dag {\n    graph[bgcolor=white, margin=1];\n    node[shape=box, style=rounded, fontname=sans,                 fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n        0[label = \"make_supplementary\", color = \"red\", style=\"rounded\"];\n        1[label = \"generate_count_table\", color = \"black\", style=\"rounded\"];\n        2[label = \"sort_bam\\nprefix: results/bowtie2/SRR935090\", color = \"black\", style=\"rounded\"];\n        3[label = \"align_to_genome\", color = \"black\", style=\"rounded\"];\n        4[label = \"get_SRA_by_accession\\nsample_id: SRR935090\", fontcolor=\"grey\", fillcolor=\"lightgrey\", color = \"grey\", style=\"rounded,dashed,filled\"];\n        5[label = \"index_genome\", color = \"grey\", fillcolor=\"lightgrey\", fontcolor=\"grey\", style=\"rounded,dashed,filled\"];\n        6[label = \"get_genome_fasta\\ngenome_id: NCTC8325\", color = \"grey\", fontcolor=\"grey\", fillcolor=\"lightgrey\", style=\"rounded,dashed,filled\"];\n        7[label = \"get_genome_gff3\\ngenome_id: NCTC8325\", color = \"grey\", fontcolor=\"grey\", fillcolor=\"lightgrey\", style=\"rounded,dashed,filled\"];\n        8[label = \"multiqc\", fontcolor=\"grey\", fillcolor=\"lightgrey\", color = \"grey\", style=\"rounded,dashed,filled\"];\n        9[label = \"fastqc\", color = \"grey\", fillcolor=\"lightgrey\", fontcolor=\"grey\", style=\"rounded,dashed,filled\"];\n        10[label = \"generate_rulegraph\", background_color=\"black\", fontcolor=\"grey\", color = \"grey\", fillcolor=\"lightgrey\", style=\"rounded,dashed,filled\"];\n        1 -&gt; 0\n        8 -&gt; 0\n        10 -&gt; 0\n        2 -&gt; 1\n        7 -&gt; 1\n        3 -&gt; 2\n        4 -&gt; 3\n        5 -&gt; 3\n        6 -&gt; 5\n        9 -&gt; 8\n        4 -&gt; 9\n}\n\n\n\n\n\n\nsnakemake_dag\n\n\n\n0\n\nmake_supplementary\n\n\n\n1\n\ngenerate_count_table\n\n\n\n1-&gt;0\n\n\n\n\n\n2\n\nsort_bam\nprefix: results/bowtie2/SRR935090\n\n\n\n2-&gt;1\n\n\n\n\n\n3\n\nalign_to_genome\n\n\n\n3-&gt;2\n\n\n\n\n\n4\n\nget_SRA_by_accession\nsample_id: SRR935090\n\n\n\n4-&gt;3\n\n\n\n\n\n9\n\nfastqc\n\n\n\n4-&gt;9\n\n\n\n\n\n5\n\nindex_genome\n\n\n\n5-&gt;3\n\n\n\n\n\n6\n\nget_genome_fasta\ngenome_id: NCTC8325\n\n\n\n6-&gt;5\n\n\n\n\n\n7\n\nget_genome_gff3\ngenome_id: NCTC8325\n\n\n\n7-&gt;1\n\n\n\n\n\n8\n\nmultiqc\n\n\n\n8-&gt;0\n\n\n\n\n\n9-&gt;8\n\n\n\n\n\n10\n\ngenerate_rulegraph\n\n\n\n10-&gt;0"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#anatomy-of-a-snakemake-rule",
    "href": "lectures/snakemake/snakemake.html#anatomy-of-a-snakemake-rule",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a Snakemake rule",
    "text": "Anatomy of a Snakemake rule"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-11",
    "href": "lectures/snakemake/snakemake.html#section-11",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "Rules are typically named and have input and/or output directives\n\nrule trim_fastq:\n    output: temp(\"{sample}.trimmed.fastq\")\n    input: \"{sample}.fastq\"\n    shell:\n        \"\"\"\n        seqtk trimfq -b 5 -e 10 {input} &gt; {output}\n        \"\"\""
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-12",
    "href": "lectures/snakemake/snakemake.html#section-12",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "Rules are typically named and have input and/or output directives\nLogfiles help with debugging and leave a “paper trail”\n\nrule trim_fastq:\n    output: temp(\"{sample}.trimmed.fastq\")\n    input: \"{sample}.fastq\"\n    log: \"logs/{sample}.trim_fastq.log\"\n    shell:\n        \"\"\"\n        seqtk trimfq -b 5 -e 10 {input} &gt; {output} 2&gt; {log}\n        \"\"\""
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-13",
    "href": "lectures/snakemake/snakemake.html#section-13",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "Rules are typically named and have input and/or output directives\nLogfiles help with debugging and leave a “paper trail”\nParams can be used to pass on settings\n\nrule trim_fastq:\n    output: temp(\"{sample}.trimmed.fastq\")\n    input: \"{sample}.fastq\"\n    log: \"logs/{sample}.trim_fastq.log\"\n    params:\n        leftTrim=5,\n        rightTrim=10\n    shell:\n      \"\"\"\n      seqtk trimfq -b {params.leftTrim} -e {params.rightTrim} {input} &gt; {output} 2&gt; {log}\n      \"\"\""
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-14",
    "href": "lectures/snakemake/snakemake.html#section-14",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "Rules are typically named and have input and/or output directives\nLogfiles help with debugging and leave a “paper trail”\nParams can be used to pass on settings\nThe threads directive specify maximum number of threads for a rule\nYou can also define resources such as disk/memory requirements and runtime\n\nrule trim_fastq:\n    output: temp(\"{sample}.trimmed.fastq\")\n    input: \"{sample}.fastq\"\n    log: \"logs/{sample}.trim_fastq.log\"\n    params:\n        leftTrim=5,\n        rightTrim=10\n    threads: 8\n    resources:\n        mem_mb=64,\n        runtime=120\n    shell:\n      \"\"\"\n      seqtk trimfq -t {threads} -b {params.leftTrim} -e {params.rightTrim} {input} &gt; {output} 2&gt; {log}\n      \"\"\""
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-15",
    "href": "lectures/snakemake/snakemake.html#section-15",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "Rules are typically named and have input and/or output directives\nLogfiles help with debugging and leave a “paper trail”\nParams can be used to pass on settings\nThe threads directive specify maximum number of threads for a rule\nYou can also define resources such as disk/memory requirements and runtime\nRules can be executed in separate software environments using either the conda or container directive\n\nrule trim_fastq:\n    output: temp(\"{sample}.trimmed.fastq\")\n    input: \"{sample}.fastq\"\n    log: \"logs/{sample}.trim_fastq.log\"\n    params:\n        leftTrim=5,\n        rightTrim=10\n    threads: 8\n    resources:\n        mem_mb=64,\n        runtime=120\n    conda: \"envs/seqtk.yaml\"\n    container: \"docker://quay.io/biocontainers/seqtk\"\n    shell:\n      \"\"\"\n      seqtk trimfq -t {threads} -b {params.leftTrim} -e {params.rightTrim} {input} &gt; {output} 2&gt; {log}\n      \"\"\""
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#section-16",
    "href": "lectures/snakemake/snakemake.html#section-16",
    "title": "Making reproducible workflows with ",
    "section": "",
    "text": "Rules are typically named and have input and/or output directives\nLogfiles help with debugging and leave a “paper trail”\nParams can be used to pass on settings\nThe threads directive specify maximum number of threads for a rule\nYou can also define resources such as disk/memory requirements and runtime\nRules can be executed in separate software environments using either the conda or container directive\n\nenvs/seqtk.yaml\nname: seqtk\nchannels:\n  - bioconda\ndependencies:\n  - seqtk"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#see-more-in-the-snakemake-documentation",
    "href": "lectures/snakemake/snakemake.html#see-more-in-the-snakemake-documentation",
    "title": "Making reproducible workflows with ",
    "section": "See more in the Snakemake documentation",
    "text": "See more in the Snakemake documentation\nhttps://snakemake.readthedocs.io/en/stable/snakefiles/rules.html"
  },
  {
    "objectID": "lectures/snakemake/snakemake.html#snakemake-commandline",
    "href": "lectures/snakemake/snakemake.html#snakemake-commandline",
    "title": "Making reproducible workflows with ",
    "section": "Snakemake commandline",
    "text": "Snakemake commandline\n\n\nGenerate the output of the first rule in Snakefile\n\n$ snakemake -s Snakefile\n\n\n\nRun the workflow in dry mode and print shell commands\n\n$ snakemake -n -p\n\n\n\nExecute the workflow with 8 cores\n\n$ snakemake --cores 8\n\n\n\nSpecify a configuration file\n\n$ snakemake --configfile config.yaml\n\n\n\nRun rules with specific conda environments\n\n$ snakemake --software-deployment-method conda\n\n\n\nRun rules with specific Apptainer or Docker containers\n\n$ snakemake --software-deployment-method apptainer"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#working-reproducibly-will-make-your-research-life-a-lot-easier",
    "href": "lectures/putting-it-together/putting-it-together.html#working-reproducibly-will-make-your-research-life-a-lot-easier",
    "title": "Putting it all together",
    "section": "Working reproducibly will make your research life a lot easier!",
    "text": "Working reproducibly will make your research life a lot easier!"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#take-control-of-your-research-by-making-its-different-components-reproducible",
    "href": "lectures/putting-it-together/putting-it-together.html#take-control-of-your-research-by-making-its-different-components-reproducible",
    "title": "Putting it all together",
    "section": "Take control of your research by making its different components reproducible",
    "text": "Take control of your research by making its different components reproducible"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#what-have-we-learned",
    "href": "lectures/putting-it-together/putting-it-together.html#what-have-we-learned",
    "title": "Putting it all together",
    "section": "What have we learned?",
    "text": "What have we learned?\n\n\n\n\n\n\nHow to use the version control system Git to track changes to code\nHow to use the package and environment manager Conda\nHow to use the workflow managers Snakemake and Nextflow\nHow to use Quarto and Jupyter to generate automated reports and to document your analyses\nHow to use Docker and Apptainer to distribute containerized computational environments"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#divide-your-work-into-distinct-projects",
    "href": "lectures/putting-it-together/putting-it-together.html#divide-your-work-into-distinct-projects",
    "title": "Putting it all together",
    "section": "Divide your work into distinct projects",
    "text": "Divide your work into distinct projects\n\n\nKeep all files needed to go from raw data to final results in a dedicated directory\nUse relevant subdirectories\nUse Git to version control your projects\nDo not store data and results/output in your Git repository\nWhen in doubt, commit often rather than not"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#find-your-own-project-structure",
    "href": "lectures/putting-it-together/putting-it-together.html#find-your-own-project-structure",
    "title": "Putting it all together",
    "section": "Find your own project structure",
    "text": "Find your own project structure\nFor example:\ncode/             Code needed to go from input files to final results\ndata/             Raw data - this should never edited\ndoc/              Documentation of the project\nenv/              Environment-related files, e.g. Conda environments or Dockerfiles\nresults/          Output from workflows and analyses\nREADME.md         Project description and instructions\n\nMore examples:\n\nhttps://github.com/NBISweden/project_template\nhttps://github.com/fasterius/nbis-support-template\nhttps://github.com/snakemake-workflows/snakemake-workflow-template"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#treasure-your-data",
    "href": "lectures/putting-it-together/putting-it-together.html#treasure-your-data",
    "title": "Putting it all together",
    "section": "Treasure your data",
    "text": "Treasure your data\n\n\nKeep your raw data read-only and static\nDon’t create different versions of the input data - write a script, Quarto document, Jupyter notebook or a Snakemake / Nextflow workflow if you need to pre-process your input data so that the steps can be recreated\nBackup! Keep redundant copies in different physical locations\nUpload your raw data as soon as possible to a public data repository"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#organize-your-coding",
    "href": "lectures/putting-it-together/putting-it-together.html#organize-your-coding",
    "title": "Putting it all together",
    "section": "Organize your coding",
    "text": "Organize your coding\n\n\nAvoid generating files interactively or doing things by hand\nWrite scripts, Quarto documents, Jupyter notebooks or Snakemake / Nextflow workflows for reproducible results to connect raw data to final results\nKeep the parameters separate (e.g. at top of file or in a separate configuration file)"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#what-is-reasonable-for-your-project",
    "href": "lectures/putting-it-together/putting-it-together.html#what-is-reasonable-for-your-project",
    "title": "Putting it all together",
    "section": "What is reasonable for your project?",
    "text": "What is reasonable for your project?"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#what-is-reasonable-for-your-project-1",
    "href": "lectures/putting-it-together/putting-it-together.html#what-is-reasonable-for-your-project-1",
    "title": "Putting it all together",
    "section": "What is reasonable for your project?",
    "text": "What is reasonable for your project?\nMinimal\nWrite code in a reproducible way and track your environment\n\nTrack your projects with a Git repository each; publish code with your results on e.g. GitHub\nUse Conda to install software in environments that can be exported and installed on a different system\nPublish your environment.yml file along with your code"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#what-is-reasonable-for-your-project-2",
    "href": "lectures/putting-it-together/putting-it-together.html#what-is-reasonable-for-your-project-2",
    "title": "Putting it all together",
    "section": "What is reasonable for your project?",
    "text": "What is reasonable for your project?\nGood\nStructure and document your code with notebooks\n\nUse Quarto or Jupyter notebooks to better keep track of and document your code\nTrack your notebooks with Git"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#what-is-reasonable-for-your-project-3",
    "href": "lectures/putting-it-together/putting-it-together.html#what-is-reasonable-for-your-project-3",
    "title": "Putting it all together",
    "section": "What is reasonable for your project?",
    "text": "What is reasonable for your project?\nGreat\nTrack the full environment and connect your code in a workflow\n\nGo one step beyond in tracking your environment using Docker or Apptainer\nConvert your code into a Snakemake / Nextflow workflow\nTrack both your image definitions (e.g. Dockerfiles) as well as your workflows with Git"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#alternatives",
    "href": "lectures/putting-it-together/putting-it-together.html#alternatives",
    "title": "Putting it all together",
    "section": "Alternatives",
    "text": "Alternatives\nVersion control\n\nGit – Widely used and a lot of tools available + GitHub/BitBucket.\nMercurial – Distributed model just like Git, close to Sourceforge.\nSubversion – Centralized model unlike git/mercurial; no local repository on your computer and somewhat easier to use."
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#alternatives-1",
    "href": "lectures/putting-it-together/putting-it-together.html#alternatives-1",
    "title": "Putting it all together",
    "section": "Alternatives",
    "text": "Alternatives\nEnvironment / package managers\n\nConda – General purpose environment and package manager. Community-hosted collections of tools at Bioconda or Conda-forge.\nPixi - General purpose environment/package manager built on the Conda ecosystem, but much faster and allows for lock-files; no ARM64 emulation.\nPip – Package manager for Python, has a large repository at PyPI.\nApt/yum/brew – Native package managers for different OS. Integrated in OS and might deal with e.g. update notifications better.\nVirtualenv – Environment manager used to set up semi-isolated python environments."
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#alternatives-2",
    "href": "lectures/putting-it-together/putting-it-together.html#alternatives-2",
    "title": "Putting it all together",
    "section": "Alternatives",
    "text": "Alternatives\nWorkflow managers\n\nSnakemake – Based on Python, easily understandable format, relies on file names.\nNextflow – Based on Groovy, uses data pipes rather than file names to construct the workflow.\nMake – Used in software development and has been around since the 70s. Flexible but notoriously obscure syntax.\nGalaxy - attempts to make computational biology accessible to researchers without programming experience by using a GUI."
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#alternatives-3",
    "href": "lectures/putting-it-together/putting-it-together.html#alternatives-3",
    "title": "Putting it all together",
    "section": "Alternatives",
    "text": "Alternatives\nLiterate programming\n\nQuarto - Developed by Posit (previously RStudio), command-line tool focused on generating high-quality documents in a language-agnostic way\nJupyter – Create and share notebooks in a variety of languages and formats by using a web browser.\nR Markdown – Developed by Posit (previously RStudio), focused on generating high-quality documents.\nZeppelin – Developed by Apache. Closely integrated with Spark for distributed computing and Big Data applications.\nBeaker – Newcomer based on IPython, just as Jupyter. Has a focus on integrating multiple languages in the same notebook."
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#alternatives-4",
    "href": "lectures/putting-it-together/putting-it-together.html#alternatives-4",
    "title": "Putting it all together",
    "section": "Alternatives",
    "text": "Alternatives\nContainerization / virtualization\n\nDocker – Used for packaging and isolating applications in containers. Dockerhub allows for convenient sharing. Requires root access.\nApptainer/Singularity – Simpler Docker alternative geared towards high performance computing. Does not require root.\nPodman - open source daemonless container tool similar to docker in many regards\nShifter – Similar ambition as Singularity, but less focus on mobility and more on resource management.\nVirtualBox/VMWare – Virtualisation rather than containerization. Less lightweight, but no reliance on host kernel.\n\nclass: center, middle"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#whats-in-it-for-me",
    "href": "lectures/putting-it-together/putting-it-together.html#whats-in-it-for-me",
    "title": "Putting it all together",
    "section": "“What’s in it for me?”",
    "text": "“What’s in it for me?”"
  },
  {
    "objectID": "lectures/putting-it-together/putting-it-together.html#nbis-bioinformatics-drop-in",
    "href": "lectures/putting-it-together/putting-it-together.html#nbis-bioinformatics-drop-in",
    "title": "Putting it all together",
    "section": "NBIS Bioinformatics drop-in",
    "text": "NBIS Bioinformatics drop-in\nAny questions related to reproducible research tools and concepts? Talk to an NBIS expert!\n\nOnline (Zoom)\nEvery Tuesday, 14.00-15.00 (except public holidays)\nCheck www.nbis.se/events for Zoom link and more info"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#what-is-jupyter",
    "href": "lectures/jupyter/jupyter.html#what-is-jupyter",
    "title": "Making reports with ",
    "section": "What is Jupyter?",
    "text": "What is Jupyter?\n\n\nAn open source project for interactive data science and computing\nAllows you to document, edit and run code directly in your browser"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#notebook-basics",
    "href": "lectures/jupyter/jupyter.html#notebook-basics",
    "title": "Making reports with ",
    "section": "Notebook basics",
    "text": "Notebook basics\n\n\n\n\n\n\n\n\n\n\nRuns as a local web server\nLoad/save/manage notebooks from the menu"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#jupyter-lab",
    "href": "lectures/jupyter/jupyter.html#jupyter-lab",
    "title": "Making reports with ",
    "section": "Jupyter lab",
    "text": "Jupyter lab\nThe next-generation interface for Jupyter\n\n\n\n\n\n\n\n\n\n\nSimilar to an integrated development environments (IDE).\nTab views, Code consoles, Show output in a separate tab, Live rendering of edits etc.\nThe jupyter lab interface can run Jupyter notebooks in the main work area"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#using-jupyter-notebooks",
    "href": "lectures/jupyter/jupyter.html#using-jupyter-notebooks",
    "title": "Making reports with ",
    "section": "Using Jupyter notebooks",
    "text": "Using Jupyter notebooks\n\n\nDocument your work in markdown…\n\n\n\n**Penguin data analysis**\n\nHere we will investigate the [Penguin dataset](https://github.com/allisonhorst/palmerpenguins).\n\n---\n\nThe species included in this set are:\n\n - _Adelie_\n - _Chinstrap_\n - _Gentoo_"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-1",
    "href": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-1",
    "title": "Making reports with ",
    "section": "Using Jupyter notebooks",
    "text": "Using Jupyter notebooks\n\n\nDocument your work in markdown…and have it rendered automatically.\n\n\n\nPenguin data analysis\nHere we will investigate the Penguin dataset.\n\nThe species included in this set are:\n\nAdelie\nChinstrap\nGentoo"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-2",
    "href": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-2",
    "title": "Making reports with ",
    "section": "Using Jupyter notebooks",
    "text": "Using Jupyter notebooks\n\n\nDocument your work in markdown…and have it rendered automatically.\nExecute code directly from the browser, with results attached to the code which generated them.\n\n\n\nimport seaborn as sns\n\ndata = sns.load_dataset(\"penguins\")\ndata.groupby(\"species\").mean(numeric_only=True)\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\nspecies\n\n\n\n\n\n\n\n\nAdelie\n38.791391\n18.346358\n189.953642\n3700.662252\n\n\nChinstrap\n48.833824\n18.420588\n195.823529\n3733.088235\n\n\nGentoo\n47.504878\n14.982114\n217.186992\n5076.016260"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-3",
    "href": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-3",
    "title": "Making reports with ",
    "section": "Using Jupyter notebooks",
    "text": "Using Jupyter notebooks\n\n\nDocument your work in markdown…and have it rendered automatically.\nExecute code directly from the browser, with results attached to the code which generated them.\nMix and match languages in addition to python.\n\n\nR\n\n%%R\nprint(paste(Sys.Date(), \": Hello World\", sep=\"\"))\n\n[1] \"2024-10-03: Hello World\""
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-4",
    "href": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-4",
    "title": "Making reports with ",
    "section": "Using Jupyter notebooks",
    "text": "Using Jupyter notebooks\n\n\nDocument your work in markdown…and have it rendered automatically.\nExecute code directly from the browser, with results attached to the code which generated them.\nMix and match languages in addition to python.\n\n\nR\n\n%%R\nprint(paste(Sys.Date(), \": Hello World\", sep=\"\"))\n\n[1] \"2024-10-03: Hello World\"\n\n\nruby\n\n%%ruby\nrequire 'date'\nprint DateTime.now(), \": Hello World!\"\n\nCouldn't find program: 'ruby'"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-5",
    "href": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-5",
    "title": "Making reports with ",
    "section": "Using Jupyter notebooks",
    "text": "Using Jupyter notebooks\n\n\nDocument your work in markdown…and have it rendered automatically.\nExecute code directly from the browser, with results attached to the code which generated them.\nMix and match languages in addition to python.\n\n\nR\n\n%%R\nprint(paste(Sys.Date(), \": Hello World\", sep=\"\"))\n\n[1] \"2024-10-03: Hello World\"\n\n\nruby\n\n%%ruby\nrequire 'date'\nprint DateTime.now(), \": Hello World!\"\n\nCouldn't find program: 'ruby'\n\n\nbash\n\n%%bash\necho \"$(date): Hello World!\"\n\nThu Oct  3 09:15:47 UTC 2024: Hello World!"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-6",
    "href": "lectures/jupyter/jupyter.html#using-jupyter-notebooks-6",
    "title": "Making reports with ",
    "section": "Using Jupyter notebooks",
    "text": "Using Jupyter notebooks\n\n\nDocument your work in markdown…and have it rendered automatically\nExecute code directly from the browser, with results attached to the code which generated them\nMix and match languages in addition to python.\nGenerate plots directly in the browser and/or save to file.\n\n\n\nsns.set_context(\"paper\", rc={\"axes.labelsize\":6})\n\n\nax = sns.pairplot(data, hue=\"species\", height=1,\n                  plot_kws=dict(s=20, linewidth=0.5),\n                  diag_kws=dict(linewidth=0.5))"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#use-cases",
    "href": "lectures/jupyter/jupyter.html#use-cases",
    "title": "Making reports with ",
    "section": "Use cases",
    "text": "Use cases\n\n\nLab notebook\nData exploration\nCode development\nReports\nInteractive dashboards\nand more…"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#sharing-notebooks",
    "href": "lectures/jupyter/jupyter.html#sharing-notebooks",
    "title": "Making reports with ",
    "section": "Sharing notebooks",
    "text": "Sharing notebooks\n\n\nPut the notebook on GitHub/Bitbucket and it will be rendered there\nExport to one of many different formats, e.g. HTML, PDF, code, slides etc.\nPaste a link to any Jupyter notebook nbviewer.jupyter.org and it will be rendered for you.\nOr generate interactive notebooks using Binder"
  },
  {
    "objectID": "lectures/jupyter/jupyter.html#for-the-tutorial",
    "href": "lectures/jupyter/jupyter.html#for-the-tutorial",
    "title": "Making reports with ",
    "section": "For the tutorial",
    "text": "For the tutorial\n\njupyter lab - will give you the updated and more advanced Jupyter lab interface\njupyter notebook - will give you the Classic notebook interface"
  },
  {
    "objectID": "lectures/git/git.html#what-is-git",
    "href": "lectures/git/git.html#what-is-git",
    "title": "Version control with ",
    "section": "What is Git?",
    "text": "What is Git?\n\n\nA widely used system for distributed version control\nKeeps a complete history of the changes you make to your files\nEach point in the history can be re-visited and compared with others\nGit tracks who contributed what to your code\nGit can help you version, backup and share your code and documents\nKind of like Dropbox, but you decide when each version is saved (plus a lot of more advanced features)\nGit is mainly used for text files, not large or binary files"
  },
  {
    "objectID": "lectures/git/git.html#git-nomenclature",
    "href": "lectures/git/git.html#git-nomenclature",
    "title": "Version control with ",
    "section": "Git nomenclature",
    "text": "Git nomenclature\n\n\nA repository is a collection that encompasses all the files and directories of a project\nA commit is a snapshot of a repository’s history, i.e. a point in development time\nDevelopment can be separated into branches, allowing for concurrent work on the same repository with simple transitions between functional and work-in-progress code\nUploading changes to a remote repository is called pushing, while downloading changes is called pulling"
  },
  {
    "objectID": "lectures/git/git.html#tracking-code-in-three-steps",
    "href": "lectures/git/git.html#tracking-code-in-three-steps",
    "title": "Version control with ",
    "section": "Tracking code in three steps",
    "text": "Tracking code in three steps\n\n\n\n\n\n\n\nDo some coding (i.e. add or change contents of files)\nStage the changes (i.e. specify which changes should be stored)\nCommit the changes (storing them in the repository’s history)"
  },
  {
    "objectID": "lectures/git/git.html#git-is-highly-versatile",
    "href": "lectures/git/git.html#git-is-highly-versatile",
    "title": "Version control with ",
    "section": "Git is highly versatile",
    "text": "Git is highly versatile\n\n\nEnsures reproducibility of your analyses, regardless of whether you’ve made additional changes to your code after the analysis is run\nEasily fix mistakes by reverting files to previous versions\nImproves your coding by giving you additional structure\nYour code has a backup in your remote repository\nEasily share your code and collaborate with your colleagues"
  },
  {
    "objectID": "lectures/containers/containers.html#what-is-docker",
    "href": "lectures/containers/containers.html#what-is-docker",
    "title": "Working with containers   ",
    "section": "What is Docker?",
    "text": "What is Docker?\n\n\nStandardized packaging for software, dependencies as well as the operating system\nDocker lets you create and run applications securely isolated in containers"
  },
  {
    "objectID": "lectures/containers/containers.html#docker-in-life-science",
    "href": "lectures/containers/containers.html#docker-in-life-science",
    "title": "Working with containers   ",
    "section": "Docker in life science",
    "text": "Docker in life science\nDocker can also be used to define software environments and settings for benchmarking studies:\n\nCAMI Challenge: an independent evaluation of several tools in the field of metagenomics.\n\n[…] We defined standards for submitting the software itself, along with parameter settings and required databases and implemented them in Docker container templates … 1\n\nSczyrba et al Nature Methods (2017) 14:1063–1071, doi.org/10.1038/nmeth.4458"
  },
  {
    "objectID": "lectures/containers/containers.html#docker-in-life-science-1",
    "href": "lectures/containers/containers.html#docker-in-life-science-1",
    "title": "Working with containers   ",
    "section": "Docker in life science",
    "text": "Docker in life science\nDocker can also be used to define software environments and settings for benchmarking studies:\n\n2nd CAMI Challenge\n\nFor reproducibility, participants could submit a Docker container containing the complete workflow, a Bioconda script or a software repository with detailed installation instructions […] 1\n\nMeyer et al Nature Methods (2022) 19:429-440, https://doi.org/10.1038/s41592-022-01431-4"
  },
  {
    "objectID": "lectures/containers/containers.html#docker-nomenclature",
    "href": "lectures/containers/containers.html#docker-nomenclature",
    "title": "Working with containers   ",
    "section": "Docker nomenclature",
    "text": "Docker nomenclature\n\n\n\n\n\n\n\n\n\nA Docker image is a stand-alone executable package of software\nA Docker container is an instance of a Docker image\nA Dockerfile is a recipe used to build a Docker image\nDocker Hub is an online service for hosting Docker images"
  },
  {
    "objectID": "lectures/containers/containers.html#an-example-using-a-different-os",
    "href": "lectures/containers/containers.html#an-example-using-a-different-os",
    "title": "Working with containers   ",
    "section": "An example: using a different OS",
    "text": "An example: using a different OS\n\nCheck OS on local machine\n$ uname -a\nDarwin johnsmbp.local 19.6.0 Darwin Kernel Version 19.6.0: [...] x86_64\n\n\nPull Ubuntu (Linux) image\n$ docker pull ubuntu:16.04\n16.04: Pulling from library/ubuntu\n22dc81ace0ea: Pull complete\n...\nDigest: sha256:e348fbbea0e0a0e73ab0370de151e7800684445c509d46195aef73e090a49bd6\nStatus: Downloaded image for ubuntu:16.04\n\n\nRun the container interactively and check OS version\n$ docker run -it ubuntu:16.04\nroot@407b0fd13fe5:/## uname -a\nLinux 407b0fd13fe5 4.9.60-linuxkit-aufs [...] x86_64 GNU/Linux"
  },
  {
    "objectID": "lectures/containers/containers.html#mounting-volumes",
    "href": "lectures/containers/containers.html#mounting-volumes",
    "title": "Working with containers   ",
    "section": "Mounting volumes",
    "text": "Mounting volumes\n\n\n\nLocal project/ directory:\n$ ls\n|- doc/\n|- data/\n|- code/\n|- logs/\n|- results/\n|- Snakefile\n|- config.yml\n|- environment.yml\n|- Dockerfile\n|- README.md\n\n\n\nDocker container file system:\n$ docker run -v $PWD/data:/home/data ubuntu:16.04\n\nls\n|- bin/\n|- dev/\n|- etc/\n|- home/\n|  |- data/\n|- lib/\n|- sys/\n|- usr/"
  },
  {
    "objectID": "lectures/containers/containers.html#what-can-i-use-docker-for",
    "href": "lectures/containers/containers.html#what-can-i-use-docker-for",
    "title": "Working with containers   ",
    "section": "What can I use Docker for?",
    "text": "What can I use Docker for?\n\n\nAs an advanced environment manager\n\ndocker run -it -v $PWD:/home my_image /bin/bash\n\n\n\nTo package your code with the environment it needs\n\ndocker run \\\n    -v $PWD/data:/home/data \\\n    -v $PWD/results:/home/results \\\n    my_image snakemake report.pdf\n\n\n\nTo package a whole project with environment, code and data (e.g. to accompany a manuscript).\n\ndocker run \\\n    -v $PWD/results:/home/results \\\n    my_image snakemake report.pdf"
  },
  {
    "objectID": "lectures/containers/containers.html#what-is-singularity",
    "href": "lectures/containers/containers.html#what-is-singularity",
    "title": "Working with containers   ",
    "section": "What is Singularity?",
    "text": "What is Singularity?\n\n\n\n\n\n\n\nAnother software for working with containers, similar to Docker\nA Singularity image is contained in a single file, facilitating portability\nDoes not require root access, making it suitable for work at HPCs"
  },
  {
    "objectID": "lectures/containers/containers.html#what-is-apptainer",
    "href": "lectures/containers/containers.html#what-is-apptainer",
    "title": "Working with containers   ",
    "section": "What is Apptainer?",
    "text": "What is Apptainer?\n\n\n\nIn 2021 Singularity joined the Linux Foundation and became Apptainer.\nThe company Sylabs still maintains Singularity as a commercial piece of software.\nSingularityCE is an Open Source project supported by Sylabs.\nThe three versions are similar today, but will diverge with time.\nApptainer is the most commonly adopted version of the scientific community."
  },
  {
    "objectID": "lectures/containers/containers.html#docker-vs.-apptainer",
    "href": "lectures/containers/containers.html#docker-vs.-apptainer",
    "title": "Working with containers   ",
    "section": "Docker vs. Apptainer",
    "text": "Docker vs. Apptainer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRuns as a daemon process with superuser privileges\nRuns as a regular user\n\n\nImages stored centrally\nImage files that you can move around.\n\n\nIsolates the host and container file system by default\nContainers have access to host file system\n\n\nWell-supported on Mac, Linux and Windows\nLimited support on Mac and Windows"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "How to work reproducibly with control and structuring of project code, environment and workflow management\n\n\nUpdated: 04-10-2024 at 18:50:24 ."
  },
  {
    "objectID": "index.html#tools-for-reproducible-research",
    "href": "index.html#tools-for-reproducible-research",
    "title": "",
    "section": "",
    "text": "How to work reproducibly with control and structuring of project code, environment and workflow management\n\n\nUpdated: 04-10-2024 at 18:50:24 ."
  },
  {
    "objectID": "home_schedule.html",
    "href": "home_schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Time\nTopic\nInstructor\n\n\n \n25-Nov-2024MonStockholm\n\n09:00 - NA\nSetting up and troubleshooting installations\n\n\n\n10:00 - NA\nIntroduction to Reproducible Research\nErik Fasterius\n\n\n10:25 - NA\nBreak\n\n\n\n10:40 - NA\nData management and project organisation\nJohn Sundh\n\n\n11:10 - NA\nVersion tracking and distributing your code\nErik Fasterius\n\n\n12:00 - NA\nLunch\n\n\n\n13:00 - NA\n… continued: Git\n\n\n\n14:40 - NA\nBreak\n\n\n\n15:00 - NA\nMastering your environment with Conda\nJohn Sundh\n\n\n16:45 - NA\nWrap-up day 1\nErik Fasterius\n \n26-Nov-2024TueStockholm\n\n09:00 - NA\nOrganise your analyses using workflow managers: Snakemake\nJohn Sundh\n\n\n10:20 - NA\nBreak\n\n\n\n10:40 - NA\n… continued: Snakemake\n\n\n\n12:00 - NA\nLunch\n\n\n\n13:00 - NA\n… continued: Snakemake\n\n\n\n14:40 - NA\nBreak\n\n\n\n15:00 - NA\nOrganise your analyses using workflow managers: Nextflow\nErik Fasterius\n\n\n16:45 - NA\nWrap-up day 2\nJohn Sundh\n\n\n18:00 - NA\nCourse dinner\n\n \n27-Nov-2024WedStockholm\n\n09:00 - NA\n… continued: Nextflow\n\n\n\n10:20 - NA\nBreak\n\n\n\n10:40 - NA\n… continued: Nextflow\n\n\n\n12:00 - NA\nLunch\n\n\n\n13:00 - NA\nWriting computational notebooks and reproducible reports: Quarto\nErik Fasterius\n\n\n14:30 - NA\nBreak\n\n\n\n14:50 - NA\n… continued: Quarto\n\n\n\n15:20 - NA\nWriting computational notebooks and reproducible reports: Jupyter\nJohn Sundh\n\n\n16:45 - NA\nWrap-up day 3\nErik Fasterius\n \n28-Nov-2024ThuStockholm\n\n09:00 - NA\n… continued: Jupyter\n\n\n\n09:45 - NA\nWorking with containers\nJohn Sundh\n\n\n10:30 - NA\nBreak\n\n\n\n10:50 - NA\n… continued: Containers\n\n\n\n12:00 - NA\nLunch\n\n\n\n13:00 - NA\n… continued: Containers\n\n\n\n14:20 - NA\nBreak\n\n\n\n14:40 - NA\n… continued: Containers\n\n\n\n16:45 - NA\nWrap-up day 4\nJohn Sundh\n \n29-Nov-2024FriStockholm\n\n09:00 - NA\nPutting it all together\nErik Fasterius\n\n\n10:20 - NA\nBreak\n\n\n\n10:40 - NA\ncontinued: Putting it all together\n\n\n\n12:00 - NA\nLunch\n\n\n\n13:00 - NA\ncontinued: Putting it all together\n\n\n\n14:20 - NA\nBreak\n\n\n\n14:40 - NA\ncontinued: Putting it all together\n\n\n\n15:45 - NA\nFinal wrap-up and end of the course\nJohn Sundh\n\n\n\n\n\n\n\n   Date    Venue    Slides    Lab    Video"
  },
  {
    "objectID": "home_contents.html",
    "href": "home_contents.html",
    "title": "Contents",
    "section": "",
    "text": "Below you can find a list of all the topics covered by the workshop and links to their respective tutorials and lectures. Please note that not all topics have a tutorial associated with them, and are only covered by a lecture. Lectures should be considered short introductions to each topic, while the tutorials themselves contain all of the material covered by the workshop.\n\n\n\n\nTopic\nLecture\nTutorial\n\n\n\n\nIntroduction\n\n\n\n\nData management\n\n\n\n\nGit\n\n\n\n\nConda\n\n\n\n\nSnakemake\n\n\n\n\nNextflow\n\n\n\n\nQuarto\n\n\n\n\nJupyter\n\n\n\n\nContainers\n\n\n\n\nPutting it all together\n\n\n\n\nMarkdown\n\n\n\n\nTake-down"
  },
  {
    "objectID": "home_precourse.html",
    "href": "home_precourse.html",
    "title": "Pre-course setup",
    "section": "",
    "text": "All of the tutorials and the material in them is dependent on the GitHub repository for the course. The first step of the setup is thus to download all the files that you will need, which is done differently depending on which operating system you have.\nOn the last day, in the Putting the pieces together session we will give examples of how we use these tools in our day-to-day work. During the course, spend some time thinking about how these tools could be useful for you in your own project(s). After you’ve gone through the tutorial you may feel that some of the tools could make your life easier from the get-go, while others may take some time to implement efficiently (and some you may never use again after the course). Our idea with the Putting the pieces together session is to have an open discussion about where to go from here."
  },
  {
    "objectID": "home_precourse.html#setup-for-mac-linux-users",
    "href": "home_precourse.html#setup-for-mac-linux-users",
    "title": "Pre-course setup",
    "section": "1 Setup for Mac / Linux users",
    "text": "1 Setup for Mac / Linux users\nFirst, cd into a directory on your computer (or create one) where it makes sense to download the course directory.\ncd /path/to/your/directory\ngit clone https://github.com/NBISweden/workshop-reproducible-research.git\ncd workshop-reproducible-research\n\nTip  If you want to revisit the material from an older instance of this course, you can do that using git switch -d tags/&lt;tag-name&gt;, e.g. git switch -d tags/course_1905. To list all available tags, use git tag. Run this command after you have cd into workshop-reproducible-research as described above. If you do that, you probably also want to view the same older version of this website. Until spring 2021, the website was hosted at ReadTheDocs. Locate the version box in the bottom right corner of the website and select the corresponding version."
  },
  {
    "objectID": "home_precourse.html#setup-for-windows-users",
    "href": "home_precourse.html#setup-for-windows-users",
    "title": "Pre-course setup",
    "section": "2 Setup for Windows users",
    "text": "2 Setup for Windows users\nUsing a Windows computer for bioinformatic work has sadly not been ideal most of the time, but large advanced in recent years have made this quite feasible through the Windows 10 Linux subsystem. This is the only setup for Windows users that we allow for participants of this course, as all the material has been created and tested to work on Unix-based systems.\nUsing the Linux subsystem will give you access to a full command-line bash shell based on Linux on your Windows 10 PC. For the difference between the Linux Bash Shell and the PowerShell on Windows 10, see e.g. this article.\nInstall Bash on Windows 10, follow the instructions at e.g. one of these resources:\n\nInstalling the Windows Subsystem and the Linux Bash\nInstalling and using Linux Bash on Windows\nInstalling Linux Bash on Windows\n\n\nNote  If you run into error messages when trying to download files through the Linux shell (e.g. curl:(6) Could not resolve host) then try adding the Google name server to the internet configuration by running sudo nano /etc/resolv.conf then add nameserver 8.8.8.8 to the bottom of the file and save it.\n\n\nImportant!  Whenever a setup instruction specifies Mac or Linux (i.e. only those two, with no alternative for Windows), please follow the Linux instructions.\n\nOpen a bash shell Linux terminal and clone the GitHub repository containing all files you will need for completing the tutorials as follows. First, cd into a directory on your computer (or create one) where it makes sense to download the course directory.\n\nTip  You can find the directory where the Linux distribution is storing all its files by typing explorer.exe .. This will launch the Windows File Explorer showing the current Linux directory. Alternatively, you can find the Windows C drive from within the bash shell Linux terminal by navigating to /mnt/c/.\n\ncd /path/to/your/directory\ngit clone https://github.com/NBISweden/workshop-reproducible-research.git\ncd workshop-reproducible-research"
  },
  {
    "objectID": "home_precourse.html#installing-git",
    "href": "home_precourse.html#installing-git",
    "title": "Pre-course setup",
    "section": "3 Installing Git",
    "text": "3 Installing Git\nChances are that you already have git installed on your computer. You can check by running e.g. git --version. If you don’t have git, install it following the instructions here. If you have a very old version of git you might want to update to a later version. If you’re on a Mac you can also install it using Homebrew and simple brew install git.\n\n3.1 Configure git\nIf it is the first time you use git on your computer, you may want to configure it so that it is aware of your username and email. These should match those that you have registered on GitHub. This will make it easier when you want to sync local changes with your remote GitHub repository.\ngit config --global user.name \"Mona Lisa\"\ngit config --global user.email \"mona_lisa@gmail.com\"\n\nTip  If you have several accounts (e.g. both a GitHub and Bitbucket account), and thereby several different usernames, you can configure git on a per-repository level. Change directory into the relevant local git repository and run git config user.name \"Mona Lisa\". This will set the default username for that repository only.\n\nYou will also need to configure the default branch name to be main instead of master:\ngit config --global init.defaultBranch \"main\"\nThe short version of why you need to do this is that GitHub uses main as the default branch while Git itself is still using master; please read the box below for more information.\n\nThe default branch name  The default branch name for Git and many of the online resources for hosting Git repositories has traditionally been master, which historically comes from the “master/slave” repositories of BitKeeper. This has been heavily discussed and in 2020 the decision was made by many (including GitHub) to start using main instead. Any repository created with GitHub uses this new naming scheme since October of 2020, and Git itself is currently discussing implementing a similar change. Git did, however, introduce the ability to set the default branch name when using git init in version 2.28, instead of using a hard-coded master. We at NBIS want to be a part of this change, so we have chosen to use main for this course.\n\n\n\n3.2 GitHub setup\nGitHub is one of several online hosting platforms for Git repositories. We’ll go through the details regarding how Git and GitHub are connected in the course itself, so for now we’ll stick to setting up your account and credentials.\nIf you have not done so already, go to github.com and create an account. You can also create an account on another online hosting service for version control, e.g. Bitbucket or GitLab. The exercises in this course are written with examples from GitHub (as that is the most popular platform with the most extensive features), but the same thing can be done on alternative services, although the exact menu structure and link placements differ.\nAny upload to and from GitHub requires you to authenticate yourself. GitHub used to allow authentication with your account and password, but this is no longer the case - using SSH keys is required instead. Knowing exactly what these are is not necessary to get them working, but we encourage you to read the box below to learn more about them! GitHub has excellent, platform-specific instructions both on how to generate and add SSH keys to your account, so please follow those instructions.\n\nSSH keys and authentication  Using SSH (Secure Shell) for authentication basically entails setting up a pair of keys: one private and one public. You keep the private key on your local computer and give the public key to anywhere you want to be able to connect to, e.g. GitHub. The public key can be used to encrypt messages that only the corresponding private key can decrypt. A simplified description of how SSH authentication works goes like this:\n\nThe client (i.e. the local computer) sends the ID of the SSH key pair it would like to use for authentication to the server (e.g. GitHub)\nIf that ID is found, the server generates a random number and encrypts this with the public key and sends it back to the client\nThe client decrypts the random number with the private key and sends it back to the server\n\nNotice that the private key always remains on the client’s side and is never transferred over the connection; the ability to decrypt messages encrypted with the public key is enough to ascertain the client’s authenticity. This is in contrast with using passwords, which are themselves sent across a connection (albeit encrypted). It is also important to note that even though the keys come in pairs it is impossible to derive the private key from the public key. If you want to read more details about how SSH authentication work you can check out this website, which has more in-depth information than we provide here."
  },
  {
    "objectID": "home_precourse.html#installing-conda",
    "href": "home_precourse.html#installing-conda",
    "title": "Pre-course setup",
    "section": "4 Installing Conda",
    "text": "4 Installing Conda\nConda is installed with a Miniforge installer specific for your operating system:\n# Install Miniforge for 64-bit Mac\ncurl -L https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-x86_64.sh -O\nbash Miniforge3-MacOSX-x86_64.sh\nrm Miniforge3-MacOSX-x86_64.sh\n# Install Miniforge for 64-bit Mac (Apple chip)\ncurl -L  https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-arm64.sh -O\nbash Miniforge3-MacOSX-arm64.sh\nrm Miniforge3-MacOSX-arm64.sh\n# Install Miniforge for 64-bit Linux\ncurl -L https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh -O\nbash Miniforge3-Linux-x86_64.sh\nrm Miniforge3-Linux-x86_64.sh\nThe installer will ask you questions during the installation:\n\nDo you accept the license terms? (Yes)\nDo you accept the installation path or do you want to choose a different one? (Probably yes)\nDo you want the installer to initialize Miniforge (Yes)\n\nRestart your shell so that the settings in ~/.bashrc or ~/.bash_profile can take effect. You can verify that the installation worked by running:\nconda --version\n\n4.1 If you already have Conda installed\nIf you already have installed Conda you can make sure you’re using the latest version by running conda update -n base conda and skip the installation instructions below.\n\n\n4.2 Configuring Conda\nAs a last step we will set up the default channels (from where packages will be searched for and downloaded if no channel is specified):\nconda config --add channels bioconda\nconda config --add channels conda-forge\nAnd we will also set so called ‘strict’ channel priority, which ensures higher stability and better performance (see details about this setting by running the following:\nconda config --set channel_priority strict\n\nImportant!  The Conda docs specify a couple of things to keep in mind when using Conda. First of all, conda should be installed in the base environment and no other packages should be installed into base. Furthermore, mixing of the conda-forge and defaults channels should be avoided as the default Anaconda channels are incompatible with conda-forge. Since we are installing from miniforge we get the conda-forge defaults without having to do anything.\n\n\n\n4.3 Conda on new Macs\nIf you have one of the newer Macs with Apple chips (the M-series) you may run into some problems with certain Conda packages that have not yet been built for the ARM64 architecture. The Rosetta software allows ARM64 Macs to use software built for the old AMD64 architecture, which means you can always fall back on creating AMD/Intel-based environments and use them in conjunction with Rosetta. This is how you do it:\nCONDA_SUBDIR=osx-64 &lt;conda-command&gt;\nconda activate &lt;env&gt;\nconda config --env --set subdir osx-64\nThe first command creates the Intel-based environment, while the last one makes sure that subsequent commands are also using the Intel architecture. If you don’t want to remember and do this manually each time you want to use AMD64/Rosetta you can check out this bash script."
  },
  {
    "objectID": "home_precourse.html#installing-snakemake",
    "href": "home_precourse.html#installing-snakemake",
    "title": "Pre-course setup",
    "section": "5 Installing Snakemake",
    "text": "5 Installing Snakemake\nWe will use Conda environments for the set up of this tutorial, but don’t worry if you don’t understand exactly what everything does - you’ll learn all the details at the course. First make sure you’re currently situated inside the tutorials directory (workshop-reproducible-research/tutorials) and then create the Conda environment like so:\nconda env create -f snakemake/environment.yml -n snakemake-env\nconda activate snakemake-env\n\nARM64 users:  Some of the packages in this environment is not available for the ARM64 architecture, so you’ll have to follow the instructions above.\n\nCheck that Snakemake is installed correctly, for example by executing snakemake --help. This should output a list of available Snakemake settings. If you get bash: snakemake: command not found then you need to go back and ensure that the Conda steps were successful. Once you’ve successfully completed the above steps you can deactivate the environment using conda deactivate and continue with the setup for the other tools."
  },
  {
    "objectID": "home_precourse.html#installing-nextflow",
    "href": "home_precourse.html#installing-nextflow",
    "title": "Pre-course setup",
    "section": "6 Installing Nextflow",
    "text": "6 Installing Nextflow\nThe easiest way to install Nextflow is the official one, which is to just run the following code:\ncurl -s https://get.nextflow.io | bash\nThis will give you the nextflow file in your current directory - move this file to a directory in your PATH, e.g. /usr/bin/.\nIf you’re getting Java-related errors, you can either try to update your Java installation (Nextflow requires Java 11 or later) or install Nextflow using conda. If you want to use Conda, navigate to workshop-reproducible-research/tutorials and create the environment:\nconda env create -f nextflow/environment.yml -n nextflow-env\nconda activate nextflow-env\n\nARM64 users:  Some of the packages in this environment is not available for the ARM64 architecture, so you’ll have to follow the instructions above.\n\nCheck that Nextflow was installed correctly by running nextflow -version. If you successfully installed Nextflow using Conda you can now deactivate the environment using conda deactivate and continue with the other setups, as needed."
  },
  {
    "objectID": "home_precourse.html#installing-quarto",
    "href": "home_precourse.html#installing-quarto",
    "title": "Pre-course setup",
    "section": "7 Installing Quarto",
    "text": "7 Installing Quarto\nInstalling Quarto is easiest by going to the official website and downloading the OS-appropriate package and following the installation instructions. You also need to install a LaTeX distribution to be able to render Quarto documents to PDF, which can be done using Quarto itself:\nquarto install tinytex\nWhile we’re not installing Quarto itself using Conda, we will install some software packages that are used in the Quarto tutorial using Conda: make sure your working directory is in the tutorials directory (workshop-reproducible-research/tutorials) and install the necessary packages defined in the environment.yml:\nconda env create -f quarto/environment.yml -n quarto-env\n\nARM64 users:  Some of the packages in this environment is not available for the ARM64 architecture, so you’ll have to follow the instructions above."
  },
  {
    "objectID": "home_precourse.html#installing-jupyter",
    "href": "home_precourse.html#installing-jupyter",
    "title": "Pre-course setup",
    "section": "8 Installing Jupyter",
    "text": "8 Installing Jupyter\nLet’s continue using Conda for installing software, since it’s so convenient to do so! Move into the tutorials directory (workshop-reproducible-research/tutorials), create a Conda environment from the jupyter/environment.yml file and test the installation of Jupyter, like so:\nconda env create -f jupyter/environment.yml -n jupyter-env\nconda activate jupyter-env\nOnce you’ve successfully completed the above steps you can deactivate the environment using conda deactivate and continue with the setup for the other tools."
  },
  {
    "objectID": "home_precourse.html#installing-docker",
    "href": "home_precourse.html#installing-docker",
    "title": "Pre-course setup",
    "section": "9 Installing Docker",
    "text": "9 Installing Docker\nInstalling Docker (specifically Docker Desktop) is quite straightforward on Mac, Windows and Linux distributions. Note that Docker runs as root, which means that you have to have sudo privileges on your computer in order to install or run Docker. When you have finished installing docker, regardless of which OS you are on, please type docker --version to verify that the installation was successful.\n\nDocker for older versions of OSX/Windows  The latest version of Docker may not work if you have an old version of either OSX or Windows. You can find older Docker versions that may be compatible for you if you go to https://docs.docker.com/desktop/ and click “Previous versions” in the left side menu.\n\n\n9.1 MacOS\nGo to docker.com and select the download option that is suitable for your computer’s architecture (i.e. if you have an Intel chip or a newer Apple M1 chip). This will download a dmg file - click on it when it’s done to start the installation. This will open up a window where you can drag the Docker.app to Applications. Close the window and click the Docker app from the Applications menu. Now it’s basically just to click “next” a couple of times and we should be good to go. You can find the Docker icon in the menu bar in the upper right part of the screen.\n\n\n9.2 Linux\nGo to the linux-install section of the Docker documentation and make sure that your computer meets the system requirements. There you can also find instructions for different Linux distributions in the left sidebar under Installation per Linux distro.\n\n\n9.3 Windows\nIn order to run Docker on Windows your computer must support Hardware Virtualisation Technology and virtualisation must be enabled. This is typically done in BIOS. Setting this is outside the scope of this tutorial, so we’ll simply go ahead as if though it’s enabled and hope that it works.\nOn Windows 10 we will install Docker for Windows, which is available at docker.com. Click the link Download from Docker Hub, and select Get Docker. Once the download is complete, execute the file and follow the instructions. You can now start Docker from the Start menu. You can search for it if you cannot find it; the Docker whale icon should appear in the task bar.\nYou will probably need to enable integration with the Linux subsystem, if you haven’t done so during the installation of Docker Desktop. Right-click on the Docker whale icon in the task bar and select Settings. Choose Resources and select WPS integration. Enable integration with the Linux subsystem and click Apply & Restart; also restart the Linux subsystem."
  },
  {
    "objectID": "home_syllabus.html",
    "href": "home_syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "SyllabusLearning outcomesEntry requirementsCode of Conduct\n\n\nThe following topics and tools are covered in the course:\n\nData management\nProject organisation\nGit\nConda\nSnakemake\nNextflow\nQuarto\nJupyter\nDocker\nApptainer\n\n\n\nAt the end of the course, students should be able to:\n\nUse good practices for data analysis and management\nClearly organise their bioinformatic projects\nUse the version control system Git to track and collaborate on code\nUse the package and environment manager Conda\nUse and develop workflows with Snakemake and Nextflow\nUse Quarto and Jupyter Notebooks to document and generate automated reports for their analyses\nUse Docker and Apptainer to distribute containerized computational environments\n\n\n\nThis is an NBIS / Elixir course. The course is open for PhD students, postdocs, group leaders and core facility staff. International applications are welcome, but we will give approximately half of the participant slots to applicants from Swedish universities, due to the national role NBIS plays in Sweden.\nThe only entry requirements for this course is a basic knowledge of Unix systems (i.e. being able to work on the command line) as well as at least a basic knowledge of either R or Python.\nDue to limited space the course can accommodate maximum of 20 participants. If we receive more applications, participants will be selected based on several criteria. Selection criteria include correct entry requirements, motivation to attend the course as well as gender and geographical balance.\nPlease note that NBIS training events do not provide any formal university credits. The training content is estimated to correspond to a certain number of credits, however the estimated credits are just guidelines. If formal credits are crucial, the student needs to confer with the home department before submitting a course application in order to establish whether the course is valid for formal credits or not.\n\n\nBy accepting to participate in the course, you agree to follow the NBIS Training Code of Conduct.\nTraining is one of the core values of NBIS, and benefits from the contributions of the entire scientific community. We value the involvement of everyone in the community. We are committed to creating a friendly and respectful place for learning, teaching and contributing. All participants in our events and communications are expected to show respect and courtesy to others.\nTo make clear what is expected, everyone participating in NBIS/ELIXIR courses is required to conform to the Code of Conduct. This Code of Conduct applies to all spaces managed by NBIS including, but not limited to, courses, email lists, and online forums such as Studium, GitHub, Slack, Twitter and LinkedIn. Course organizers and teachers are expected to assist with the enforcement of the Code of Conduct.\nWe are dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. By participating in this event, participants accept to abide by the NBIS Code of Conduct and accept the procedures by which any Code of Conduct incidents are resolved. Any form of behaviour to exclude, intimidate, or cause discomfort is a violation of the Code of Conduct. In order to foster a positive and professional learning environment we encourage the following kinds of behaviours in all platforms and training events:\n\nUse welcoming and inclusive language\nBe respectful of different viewpoints and experiences\nGracefully accept constructive criticism\nFocus on what is best to all those involved in this training event\nShow courtesy and respect towards everyone involved in this training event\n\nThe NBIS Training Coordinator is responsible for enforcing the Code of Conduct, and may be contacted by emailing education@nbis.se. All reports will be reviewed and will be kept confidential. If you believe someone is violating the Code of Conduct, we ask that you report it to the NBIS Training coordinator, who will take the appropriate action to address the situation.\nFor an extended description please see the ELIXIR Code of Conduct."
  },
  {
    "objectID": "lectures/conda/conda.html#the-problem",
    "href": "lectures/conda/conda.html#the-problem",
    "title": "Managing software environments with  ",
    "section": "The problem",
    "text": "The problem\n\n\nFull reproducibility requires the possibility to recreate the system that was originally used to generate the results."
  },
  {
    "objectID": "lectures/conda/conda.html#conda-is-a-package-dependency-and-environment-manager",
    "href": "lectures/conda/conda.html#conda-is-a-package-dependency-and-environment-manager",
    "title": "Managing software environments with  ",
    "section": "Conda is a package, dependency, and environment manager",
    "text": "Conda is a package, dependency, and environment manager\n\npackage: any type of program (e.g. multiqc, snakemake etc.)\n\n\n\nflowchart LR\n    multiqc(multiqc)\n\n\n\n\nflowchart LR\n    multiqc(multiqc)"
  },
  {
    "objectID": "lectures/conda/conda.html#conda-is-a-package-dependency-and-environment-manager-1",
    "href": "lectures/conda/conda.html#conda-is-a-package-dependency-and-environment-manager-1",
    "title": "Managing software environments with  ",
    "section": "Conda is a package, dependency, and environment manager",
    "text": "Conda is a package, dependency, and environment manager\n\npackage: any type of program (e.g. multiqc, snakemake etc.)\ndependency: other software required by a package\n\n\n\nflowchart LR\n    multiqc(multiqc) -.-&gt; numpy(numpy)\n    multiqc -.-&gt; matplotlib(matplotlib)\n    multiqc -.-&gt; python(python)\n\n\n\n\nflowchart LR\n    multiqc(multiqc) -.-&gt; numpy(numpy)\n    multiqc -.-&gt; matplotlib(matplotlib)\n    multiqc -.-&gt; python(python)"
  },
  {
    "objectID": "lectures/conda/conda.html#conda-is-a-package-dependency-and-environment-manager-2",
    "href": "lectures/conda/conda.html#conda-is-a-package-dependency-and-environment-manager-2",
    "title": "Managing software environments with  ",
    "section": "Conda is a package, dependency, and environment manager",
    "text": "Conda is a package, dependency, and environment manager\n\npackage: any type of program (e.g. multiqc, snakemake etc.)\ndependency: other software required by a package\n\ndependencies in turn have their own dependencies\n\n\n\n\nflowchart LR\n    multiqc(multiqc) -.-&gt; numpy(numpy)\n    multiqc -.-&gt; matplotlib(matplotlib)\n    multiqc -.-&gt; python(python)\n    matplotlib -.-&gt; python\n    matplotlib -.-&gt; numpy\n    matplotlib -.-&gt; fonttools(fonttools)\n    numpy -.-&gt; python\n    numpy -.-&gt; libcxx(libcxx)\n\n\n\n\nflowchart LR\n    multiqc(multiqc) -.-&gt; numpy(numpy)\n    multiqc -.-&gt; matplotlib(matplotlib)\n    multiqc -.-&gt; python(python)\n    matplotlib -.-&gt; python\n    matplotlib -.-&gt; numpy\n    matplotlib -.-&gt; fonttools(fonttools)\n    numpy -.-&gt; python\n    numpy -.-&gt; libcxx(libcxx)"
  },
  {
    "objectID": "lectures/conda/conda.html#conda-is-a-package-dependency-and-environment-manager-3",
    "href": "lectures/conda/conda.html#conda-is-a-package-dependency-and-environment-manager-3",
    "title": "Managing software environments with  ",
    "section": "Conda is a package, dependency, and environment manager",
    "text": "Conda is a package, dependency, and environment manager\n\npackage: any type of program (e.g. multiqc, snakemake etc.)\ndependency: other software required by a package\n\ndependencies in turn have their own dependencies\n\nenvironment: a distinct collection of packages\n\n\n\nflowchart LR\n    subgraph environment\n    style environment fill:#00000000, stroke-width:1px\n    direction LR\n    multiqc(multiqc) -.-&gt; numpy(numpy)\n    multiqc -.-&gt; matplotlib(matplotlib)\n    multiqc -.-&gt; python(python)\n    matplotlib -.-&gt; python\n    matplotlib -.-&gt; numpy\n    matplotlib -.-&gt; fonttools(fonttools)\n    numpy-.-&gt;python\n    numpy -.-&gt; libcxx(libcxx)\n    end\n\n\n\n\nflowchart LR\n    subgraph environment\n    style environment fill:#00000000, stroke-width:1px\n    direction LR\n    multiqc(multiqc) -.-&gt; numpy(numpy)\n    multiqc -.-&gt; matplotlib(matplotlib)\n    multiqc -.-&gt; python(python)\n    matplotlib -.-&gt; python\n    matplotlib -.-&gt; numpy\n    matplotlib -.-&gt; fonttools(fonttools)\n    numpy-.-&gt;python\n    numpy -.-&gt; libcxx(libcxx)\n    end"
  },
  {
    "objectID": "lectures/conda/conda.html#conda-channels",
    "href": "lectures/conda/conda.html#conda-channels",
    "title": "Managing software environments with  ",
    "section": "Conda channels",
    "text": "Conda channels\nChannels are remote directories containing packages\n\n\nflowchart TD\n    ch1[(channel1)] --- p1[package1]\n    ch1[(channel1)] --- p2[package2]\n    ch1[(channel1)] --- p3[package3]\n\n    ch2[(channel2)] --- p4[package4]\n    ch2[(channel2)] --- p5[package5]\n    ch2[(channel2)] --- p6[package6]\n\n\n\n\nflowchart TD\n    ch1[(channel1)] --- p1[package1]\n    ch1[(channel1)] --- p2[package2]\n    ch1[(channel1)] --- p3[package3]\n\n    ch2[(channel2)] --- p4[package4]\n    ch2[(channel2)] --- p5[package5]\n    ch2[(channel2)] --- p6[package6]"
  },
  {
    "objectID": "lectures/conda/conda.html#conda-channels-1",
    "href": "lectures/conda/conda.html#conda-channels-1",
    "title": "Managing software environments with  ",
    "section": "Conda channels",
    "text": "Conda channels\nTwo common examples are:\n\nbioconda (a channel specializing in bioinformatics software)\nconda-forge (a community-led channel made up of thousands of contributors)\n\n\n\nflowchart TD\n    ch1[(bioconda)] --- p1[bowtie2]\n    ch1[(bioconda)] --- p2[fastqc]\n    ch1[(bioconda)] --- p3[snakemake]\n\n    ch2[(conda-forge)] --- p4[numpy]\n    ch2[(conda-forge)] --- p5[jupyter]\n    ch2[(conda-forge)] --- p6[wget]\n\n\n\n\nflowchart TD\n    ch1[(bioconda)] --- p1[bowtie2]\n    ch1[(bioconda)] --- p2[fastqc]\n    ch1[(bioconda)] --- p3[snakemake]\n\n    ch2[(conda-forge)] --- p4[numpy]\n    ch2[(conda-forge)] --- p5[jupyter]\n    ch2[(conda-forge)] --- p6[wget]"
  },
  {
    "objectID": "lectures/conda/conda.html#conda-channels-2",
    "href": "lectures/conda/conda.html#conda-channels-2",
    "title": "Managing software environments with  ",
    "section": "Conda channels",
    "text": "Conda channels\nTwo common examples are:\n\nbioconda (a channel specializing in bioinformatics software)\nconda-forge (a community-led channel made up of thousands of contributors)\n\n\n\nflowchart TD\n    ch1[(bioconda)] --- p1[bowtie2]\n    ch1[(bioconda)] --- p2[fastqc]\n    ch1[(bioconda)] --- p3[snakemake]\n\n    ch2[(conda-forge)] --- p4[numpy]\n    ch2[(conda-forge)] --- p5[jupyter]\n    ch2[(conda-forge)] --- p6[wget]\n\n    p5 -.-&gt; l1([conda install -c conda-forge -c bioconda snakemake jupyter])\n    p3 -.-&gt; l1\n\n\n\n\nflowchart TD\n    ch1[(bioconda)] --- p1[bowtie2]\n    ch1[(bioconda)] --- p2[fastqc]\n    ch1[(bioconda)] --- p3[snakemake]\n\n    ch2[(conda-forge)] --- p4[numpy]\n    ch2[(conda-forge)] --- p5[jupyter]\n    ch2[(conda-forge)] --- p6[wget]\n\n    p5 -.-&gt; l1([conda install -c conda-forge -c bioconda snakemake jupyter])\n    p3 -.-&gt; l1"
  },
  {
    "objectID": "lectures/conda/conda.html#defining-and-sharing-environments",
    "href": "lectures/conda/conda.html#defining-and-sharing-environments",
    "title": "Managing software environments with  ",
    "section": "Defining and sharing environments",
    "text": "Defining and sharing environments\nDefine a Conda environment in an environment.yml file:\nchannels:\n  - conda-forge\n  - bioconda\ndependencies:\n  - fastqc=0.11\n  - sra-tools=2.8\n  - snakemake=4.3.0\n  - multiqc=1.3\n  - bowtie2=2.3\n  - samtools=1.6\n  - htseq=0.9\n  - graphviz=2.38.0"
  },
  {
    "objectID": "lectures/conda/conda.html#defining-and-sharing-environments-1",
    "href": "lectures/conda/conda.html#defining-and-sharing-environments-1",
    "title": "Managing software environments with  ",
    "section": "Defining and sharing environments",
    "text": "Defining and sharing environments\n\nUpdate an existing environment:\n\nconda env update -f environment.yml"
  },
  {
    "objectID": "lectures/conda/conda.html#defining-and-sharing-environments-2",
    "href": "lectures/conda/conda.html#defining-and-sharing-environments-2",
    "title": "Managing software environments with  ",
    "section": "Defining and sharing environments",
    "text": "Defining and sharing environments\n\nUpdate an existing environment:\n\nconda env update -f environment.yml\n\nExport environment (including all dependencies) to a file:\n\nconda env export &gt; environment.yml"
  },
  {
    "objectID": "lectures/conda/conda.html#defining-and-sharing-environments-3",
    "href": "lectures/conda/conda.html#defining-and-sharing-environments-3",
    "title": "Managing software environments with  ",
    "section": "Defining and sharing environments",
    "text": "Defining and sharing environments\n\nUpdate an existing environment:\n\nconda env update -f environment.yml\n\nExport environment (including all dependencies) to a file:\n\nconda env export &gt; environment.yml\n\nExport historical environment (only packages explicitly installed):\n\nconda env export --from-history &gt; environment.yml"
  },
  {
    "objectID": "lectures/conda/conda.html#conda-anaconda-miniconda-miniforge",
    "href": "lectures/conda/conda.html#conda-anaconda-miniconda-miniforge",
    "title": "Managing software environments with  ",
    "section": "Conda, Anaconda, Miniconda, Miniforge…",
    "text": "Conda, Anaconda, Miniconda, Miniforge…\n\n\nConda: The package manager itself, written in python\nAnaconda:\n\nThe company behind Conda itself\nAn installer for Conda containing over 7,500 open-source packages\nA cloud service where conda packages are hosted (anaconda.com)\n\nMiniconda: A minimal installer for Conda, pre-configured to use the default channel\nMiniforge: A minimal installer for Conda, pre-configured to use the conda-forge channel"
  },
  {
    "objectID": "lectures/data-management/data-management.html#data-mismanagement-in-practice",
    "href": "lectures/data-management/data-management.html#data-mismanagement-in-practice",
    "title": "Managing your data",
    "section": "Data (mis)management in practice",
    "text": "Data (mis)management in practice\n\n\n\n\n\n\n\n\n\nRaw data\nMetadata\n\n\n\n\nData acquisition\nData arrives in cumbersome and proprietary format\nIn researcher’s lab journal\n\n\nAnalysis\nGets converted to format of choice. Original files (and conversion settings) are lost\nHard-coded in various analysis scripts\n\n\nFirst submission\n\nMailed back and forth between collaborators in ever-changing (but nicely coloured) Excel sheets\n\n\nReview\nLeads a quiet life on the HPC cluster, until the project expires and the data has to be urgently retrieved\n\n\n\nSecond submission\nEnds its days on an external hard drive on the researcher’s desk\nReformatted and included as PDF in the supplementary\n\n\nPublication\n“Data available upon request”"
  },
  {
    "objectID": "lectures/data-management/data-management.html#fair-data",
    "href": "lectures/data-management/data-management.html#fair-data",
    "title": "Managing your data",
    "section": "FAIR data",
    "text": "FAIR data\nStrive to make your data FAIR1 for both machines and humans:\n\nFindable\nAccessible\nInteroperable\nReusable\n\nWilkinson, Mark et al. “The FAIR Guiding Principles for scientific data management and stewardship”. Scientific Data 3, Article number: 160018 (2016)"
  },
  {
    "objectID": "lectures/data-management/data-management.html#data-management-plan",
    "href": "lectures/data-management/data-management.html#data-management-plan",
    "title": "Managing your data",
    "section": "Data management plan",
    "text": "Data management plan\n\n\nCheck requirements of funding agency and field of research 1\nDetermine required storage space for short and long term\nProvide helpful metadata\nConsider legal/ethical restrictions if working with sensitive data\nFind suitable data repositories\nStrive towards uploading data to its final destination at the beginning of a project\n\n\nVR data management plan"
  },
  {
    "objectID": "lectures/data-management/data-management.html#data-sharing",
    "href": "lectures/data-management/data-management.html#data-sharing",
    "title": "Managing your data",
    "section": "Data sharing",
    "text": "Data sharing\n\n\n\n\n\nWhy Open Access?\n\nPublicly funded research should be unrestricted\nPublished results should be verifiable by others\nEnables other to build upon previous work"
  },
  {
    "objectID": "lectures/data-management/data-management.html#organizing-your-projects",
    "href": "lectures/data-management/data-management.html#organizing-your-projects",
    "title": "Managing your data",
    "section": "Organizing your projects",
    "text": "Organizing your projects\nWhich sample file represents the most up to date version?\n$ ls -l data/\n-rw-r--r--  user  staff  Nov 12 22:00 samples.mat\n-rw-r--r--  user  staff  Nov 16 11:39 samplesFinal.mat\n-rw-r--r--  user  staff  Nov 18 22:41 samplesFinalV2.mat\n-rw-r--r--  user  staff  Nov 18 13:25 samplesUSE_THIS_ONE.mat\n-rw-r--r--  user  staff  Nov 15 22:39 samplesV2.mat"
  },
  {
    "objectID": "lectures/data-management/data-management.html#the-project-directory",
    "href": "lectures/data-management/data-management.html#the-project-directory",
    "title": "Managing your data",
    "section": "The project directory",
    "text": "The project directory\nThe first step towards working reproducibly: Get organized!\n\n\nDivide your work into distinct projects\nKeep all files needed to go from raw data to final results in a dedicated directory\nUse relevant subdirectories"
  },
  {
    "objectID": "lectures/data-management/data-management.html#there-are-many-ways-to-organize-a-project",
    "href": "lectures/data-management/data-management.html#there-are-many-ways-to-organize-a-project",
    "title": "Managing your data",
    "section": "There are many ways to organize a project",
    "text": "There are many ways to organize a project\n\n\n\nA simple but effective example is the following:\ncode/             Code needed to go from input files to final results\ndata/             Raw data - this should never edited\ndoc/              Documentation of the project\nenv/              Environment-related files, e.g. Conda environments or Dockerfiles\nresults/          Output from workflows and analyses\nREADME.md         Project description and instructions\n\n\n\nA Snakemake-based example: snakemake-workflows/template\nconfig/\ndata/\ndoc/\nenv/\nresults/\nworkflow/\n  Snakefile\nLICENSE\nREADME.md\n\nA Nextflow-based example: fasterius/nbis-support-template\nbin/\ndata/\ndoc/\nenv/\nresults/\nREADME.md\nLICENSE\nmain.nf\nnextflow.config"
  },
  {
    "objectID": "lectures/data-management/data-management.html#helpful-tools",
    "href": "lectures/data-management/data-management.html#helpful-tools",
    "title": "Managing your data",
    "section": "Helpful tools",
    "text": "Helpful tools\n\nSyntax highlighting, autocomplete, Git integration, etc.:\n\nVSCode\nRStudio\nPyCharm\n\n\n\nWorking in an HPC over SSH in the command line:\n\nNano\nVim\nNeovim"
  },
  {
    "objectID": "lectures/data-management/data-management.html#topics-for-discussion",
    "href": "lectures/data-management/data-management.html#topics-for-discussion",
    "title": "Managing your data",
    "section": "Topics for discussion",
    "text": "Topics for discussion\n\nDo you organize your work in distinct projects?\nHow do you organize your files in this context?\nAre you happy with the way you work today?\nDoes your group have a data management plan in place?\nDo you know “your” repositories and how to submit data to them?"
  },
  {
    "objectID": "lectures/introduction/introduction.html#course-content",
    "href": "lectures/introduction/introduction.html#course-content",
    "title": "Introduction",
    "section": "Course content",
    "text": "Course content\n\n\nGood practices for working with data\nHow to use the version control system Git to track changes to code\nHow to use the package and environment manager Conda\nHow to use the workflow managers Snakemake and Nextflow\nHow to generate automated reports using Quarto and Jupyter\nHow to use Docker and Apptainer to distribute containerized computational environments"
  },
  {
    "objectID": "lectures/introduction/introduction.html#the-teachers",
    "href": "lectures/introduction/introduction.html#the-teachers",
    "title": "Introduction",
    "section": "The Teachers",
    "text": "The Teachers\n\n\n\n\n\n\nJohn Sundh\n\n\n\n\n\n\n\nErik Fasterius\n\n\n\n\n\n\n\nVerena Kutschera\n\n\n\n\n\n\n\n\n\nTomas Larsson\n\n\n\n\n\n\n\nLokeshwaran Manoharan\n\n\n\n\n\n\n\nEstelle Proux-Wera"
  },
  {
    "objectID": "lectures/introduction/introduction.html#what-is-nbis",
    "href": "lectures/introduction/introduction.html#what-is-nbis",
    "title": "Introduction",
    "section": "What is NBIS?",
    "text": "What is NBIS?\n\nNational Bioinformatics Infrastructure Sweden\n\n\n\nA distributed national bioinformatics infrastructure supporting life sciences in Sweden\nProvides hands-on bioinformatic support, training, infrastructure and a weekly drop-in\nSituated throughout Sweden\nProvides wide-spectrum support in the fields of bioinformatics, bioimage informatics, data management, imaging AI, development of systems and tools as well as national compute resources.\nRead more at nbis.se"
  },
  {
    "objectID": "lectures/introduction/introduction.html#what-is-reproducibility",
    "href": "lectures/introduction/introduction.html#what-is-reproducibility",
    "title": "Introduction",
    "section": "What is reproducibility?",
    "text": "What is reproducibility?"
  },
  {
    "objectID": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility",
    "href": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility",
    "title": "Introduction",
    "section": "Why all the talk about reproducibility?",
    "text": "Why all the talk about reproducibility?\n\n\nThe Reproducibility project set out to replicate 100 experiments published in high-impact psychology journals. 1\n\nAbout one-half to two-thirds of the original findings could not be observed in the replication study.\n\n\n\n\n“Estimating the reproducibility of psychological science”. Science. 349"
  },
  {
    "objectID": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility-1",
    "href": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility-1",
    "title": "Introduction",
    "section": "Why all the talk about reproducibility?",
    "text": "Why all the talk about reproducibility?\n\n\nA survey in Nature revealed that irreproducible experiments are a problem across all domains of science.1\n\n\n\n\n“1,500 scientists lift the lid on reproducibility”, Nature. 533: 452–454"
  },
  {
    "objectID": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility-2",
    "href": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility-2",
    "title": "Introduction",
    "section": "Why all the talk about reproducibility?",
    "text": "Why all the talk about reproducibility?\n\n\nMedicine is among the most affected research fields. A study in Nature found that 47 out of 53 medical research papers focused on cancer research were irreproducible.1\n\n\n\n\n“Raise standards for preclinical cancer research. Nature, 483(7391), 531-533."
  },
  {
    "objectID": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility-3",
    "href": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility-3",
    "title": "Introduction",
    "section": "Why all the talk about reproducibility?",
    "text": "Why all the talk about reproducibility?\nReplication of 18 articles on microarray-based experiments published in  Nature Genetics in 2005 & 20061\n\nlibrary(ggplot2)\nlibrary(gtable)\nblank_theme &lt;- theme_minimal() +\n    theme(\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        panel.border = element_blank(),\n        panel.grid   = element_blank(),\n        axis.ticks   = element_blank(),\n        legend.title = element_blank())\n\n\nitems = c(\"... in principle\",\n          \"... with some discrepancies\",\n          \"... from processed data with some discrepancies\",\n          \"... partially with some discrepancies\",\n          \"Cannot reproduce\")\nioannidis_1 &lt;- data.frame(\n    result = factor(items, levels = items),\n    value  = c(2, 1, 4, 1, 10))\nitems = c(\"Data not available\",\n          \"Software not available\",\n          \"Methods unclear\",\n          \"Different result\")\nioannidis_2 &lt;- data.frame(\n    result = factor(items, levels = items),\n    value  = c(5, 1, 2, 2))\n\n\npie_1_colours &lt;- c(\"#4D702D\",\"#A1C880\",\"#F5E959\",\"#E6A72E\",\"#BA382F\")\nggplot(ioannidis_1, aes(x    = \"\",\n                        y    = value,\n                        fill = result)) +\n    geom_bar(width = 1,\n             stat  = \"identity\",\n             color = \"white\") +\n    coord_polar(\"y\", start = 0) +\n    scale_fill_manual(values = pie_1_colours) +\n    blank_theme +\n    theme(axis.text.x     = element_blank(),\n          legend.text     = element_text(size = 18),\n          legend.position = \"right\") +\n    guides(fill = guide_legend(reverse = TRUE))\n\n\n\n\n\n\n\n\n“Repeatability of published microarray gene expression analyses. Nature genetics, 41(2), 149-155."
  },
  {
    "objectID": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility-4",
    "href": "lectures/introduction/introduction.html#why-all-the-talk-about-reproducibility-4",
    "title": "Introduction",
    "section": "Why all the talk about reproducibility?",
    "text": "Why all the talk about reproducibility?\nReplication of 18 articles on microarray-based experiments published in  Nature Genetics in 2005 & 20061\n\npie_2_colours &lt;- c(\"#E5876B\",\"#BC5B33\",\"#A2100C\",\"#C8325E\")\nggplot(ioannidis_2, aes(x    = \"\",\n                        y    = value,\n                        fill = result)) +\n    geom_bar(width = 1,\n             stat  = \"identity\",\n             color = \"white\") +\n    coord_polar(\"y\", start = 0) +\n    scale_fill_manual(values = pie_2_colours) +\n    blank_theme +\n    theme(axis.text.x      = element_blank(),\n          legend.position  = \"right\",\n          legend.text      = element_text(size = 18),\n          legend.direction = \"vertical\",\n          plot.margin      = grid::unit(c(5, 5, 5, 5), 'lines'))\n\n\n\n\n\n\n\n\n“Repeatability of published microarray gene expression analyses. Nature genetics, 41(2), 149-155."
  },
  {
    "objectID": "lectures/introduction/introduction.html#reproducibility-is-rarer-than-you-think",
    "href": "lectures/introduction/introduction.html#reproducibility-is-rarer-than-you-think",
    "title": "Introduction",
    "section": "Reproducibility is rarer than you think",
    "text": "Reproducibility is rarer than you think\nThe results of only 26% out of 204 randomly selected papers in the journal Science could be reproduced. 1\n\n\n“Many journals are revising author guidelines to include data and code availability.”\n\n\n\n\n“(…) an improvement over no policy, but currently insufficient for reproducibility.”\n\n\n“An empirical analysis of journal policy effectiveness for computational reproducibility”. PNAS. 115 (11): 2584-2589"
  },
  {
    "objectID": "lectures/introduction/introduction.html#reproducibility-is-rarer-than-you-think-1",
    "href": "lectures/introduction/introduction.html#reproducibility-is-rarer-than-you-think-1",
    "title": "Introduction",
    "section": "Reproducibility is rarer than you think",
    "text": "Reproducibility is rarer than you think\nThere are many so-called excuses not to work reproducibly:\n\n\n\n\n\n“Thank you for your interest in our paper. For the [redacted] calculations I used my own code, and there is no public version of this code, which could be downloaded. Since this code is not very user-friendly and is under constant development I prefer not to share this code.”\n\n\n\n\n\n\n“We do not typically share our internal data or code with people outside our collaboration.”\n\n\n\n\n\n\n“When you approach a PI for the source codes and raw data, you better explain who you are, whom you work for, why you need the data and what you are going to do with it.”\n\n\n\n\n\n“I have to say that this is a very unusual request without any explanation! Please ask your supervisor to send me an email with a detailed, and I mean detailed, explanation.”"
  },
  {
    "objectID": "lectures/introduction/introduction.html#what-does-reproducible-research-mean",
    "href": "lectures/introduction/introduction.html#what-does-reproducible-research-mean",
    "title": "Introduction",
    "section": "What does reproducible research mean?",
    "text": "What does reproducible research mean?\n\n\n\n\n\n\n\n\nData\n\n\n\n\n\nSame\n\n\nDifferent\n\n\n\n\nCode\n\n\nSame\n\n\nReproducible\n\n\nReplicable\n\n\n\n\nDifferent\n\n\nRobust\n\n\nGeneralisable\n\n\n\n\n\n\n\n\n\n\n\n\n“Why call the course Reproducible Research, when it could just as well be called Research?”\n\n\n- Niclas Jareborg, NBIS data management expert"
  },
  {
    "objectID": "lectures/introduction/introduction.html#how-are-you-handling-your-data",
    "href": "lectures/introduction/introduction.html#how-are-you-handling-your-data",
    "title": "Introduction",
    "section": "How are you handling your data?",
    "text": "How are you handling your data?\n\nDecent:\n\nData available on request\nAll metadata required for generating the results available\n\n\n\nGood:\n\nRaw data deposited in public repositories\nIf the raw data needed preprocessing, scripts were used rather than modifying it manually\n\n\n\nGreat:\n\nSection in the paper or online repository (e.g. GitHub) to aid in reproduction\nUsed non-proprietary and machine-readable formats, e.g. .csv rather than .xls.\n\n\n\n\nIf you want to learn more about data management in-depth, NBIS has a course for you: Introduction to Data Management Practices"
  },
  {
    "objectID": "lectures/introduction/introduction.html#how-are-you-handling-your-code",
    "href": "lectures/introduction/introduction.html#how-are-you-handling-your-code",
    "title": "Introduction",
    "section": "How are you handling your code?",
    "text": "How are you handling your code?\n\nDecent:\n\nAll code for generating results from processed data available on request\n\n\n\nGood:\n\nAll code for generating results from raw data is available\nThe code is publicly available with timestamps or tags\n\n\n\nGreat:\n\nCode is documented and contains instructions for reproducing results\nSeeds were used and documented for heuristic methods"
  },
  {
    "objectID": "lectures/introduction/introduction.html#how-are-you-handling-your-environment",
    "href": "lectures/introduction/introduction.html#how-are-you-handling-your-environment",
    "title": "Introduction",
    "section": "How are you handling your environment?",
    "text": "How are you handling your environment?\n\nDecent:\n\nKey programs used are mentioned in the materials and methods section\n\n\n\nGood:\n\nList of all programs used and their respective versions are available\n\n\n\nGreat:\n\nInstructions for reproducing the whole environment publicly available"
  },
  {
    "objectID": "lectures/introduction/introduction.html#whats-in-it-for-me",
    "href": "lectures/introduction/introduction.html#whats-in-it-for-me",
    "title": "Introduction",
    "section": "“What’s in it for me?”",
    "text": "“What’s in it for me?”\n\nBefore the project:\n\nImproved structure and organization\nForced to think about scope and limitations\n\n\n\nDuring the project:\n\nEasier to re-run analyses and generate results after updates and/or changes\nCloser interaction between collaborators\nMuch of the manuscript “writes itself”\n\n\n\nAfter the project:\n\nFaster resumption of research by others (or, more likely, your future self)\nIncreased visibility in the scientific community"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#nextflow-features",
    "href": "lectures/nextflow/nextflow.html#nextflow-features",
    "title": "Making reproducible workflows with ",
    "section": "Nextflow features",
    "text": "Nextflow features\n\n\nGeneralisable\nPortable\nScalable\nPlatform-agnostic\nBased on Groovy and Java\nLarge active community in e.g. nf-core"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#concepts-and-nomenclature",
    "href": "lectures/nextflow/nextflow.html#concepts-and-nomenclature",
    "title": "Making reproducible workflows with ",
    "section": "Concepts and nomenclature",
    "text": "Concepts and nomenclature\n\n\n\n\n\n\n\nChannels contain data, e.g. input files\nProcesses run some kind of code, e.g. a script or a program\nTasks are instances of a process, one per process input\nEach task is run in its own, isolated sub-directory"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#anatomy-of-a-process",
    "href": "lectures/nextflow/nextflow.html#anatomy-of-a-process",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a process",
    "text": "Anatomy of a process\nprocess GET_SRA_BY_ACCESSION {\n\n    input:\n    val(sample)\n\n    output:\n    path(\"${sample}.fastq.gz\")\n\n    script:\n    \"\"\"\n    fastq-dump ${sample} &gt; ${sample}.fastq.gz\n    \"\"\"\n}"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#anatomy-of-a-process-1",
    "href": "lectures/nextflow/nextflow.html#anatomy-of-a-process-1",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a process",
    "text": "Anatomy of a process\nprocess GET_SRA_BY_ACCESSION {\n\n    input:\n    val(sample)\n\n    output:\n    tuple val(sample), path(\"${sample}.fastq.gz\")\n\n    script:\n    \"\"\"\n    fastq-dump ${sample} &gt; ${sample}.fastq.gz\n    \"\"\"\n}"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#anatomy-of-a-process-2",
    "href": "lectures/nextflow/nextflow.html#anatomy-of-a-process-2",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a process",
    "text": "Anatomy of a process\nprocess GET_SRA_BY_ACCESSION {\n\n    cpus 2\n    memory '8 GB'\n\n    input:\n    val(sample)\n\n    output:\n    tuple val(sample), path(\"${sample}.fastq.gz\")\n\n    script:\n    \"\"\"\n    fastq-dump ${sample} &gt; ${sample}.fastq.gz\n    \"\"\"\n}"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#anatomy-of-a-process-3",
    "href": "lectures/nextflow/nextflow.html#anatomy-of-a-process-3",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a process",
    "text": "Anatomy of a process\nprocess GET_SRA_BY_ACCESSION {\n\n    cpus 2\n    memory '8 GB'\n\n    conda 'sra-tools=2.11.0'\n    container 'ncbi/sra-tools:2.11.0'\n\n    input:\n    val(sample)\n\n    output:\n    tuple val(sample), path(\"${sample}.fastq.gz\")\n\n    script:\n    \"\"\"\n    fastq-dump ${sample} &gt; ${sample}.fastq.gz\n    \"\"\"\n}"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#anatomy-of-a-process-4",
    "href": "lectures/nextflow/nextflow.html#anatomy-of-a-process-4",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a process",
    "text": "Anatomy of a process\nprocess GET_SRA_BY_ACCESSION {\n\n    cpus 2\n    memory '8 GB'\n\n    conda 'sra-tools=2.11.0'\n    container 'ncbi/sra-tools:2.11.0'\n\n    input:\n    val(sample)\n\n    output:\n    tuple val(sample), path(\"${sample}.fastq.gz\")\n\n    script:\n    \"\"\"\n    fastq-dump ${sample} -X {params.depth} &gt; ${sample}.fastq.gz\n    \"\"\"\n}"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#anatomy-of-a-workflow",
    "href": "lectures/nextflow/nextflow.html#anatomy-of-a-workflow",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a workflow",
    "text": "Anatomy of a workflow\nworkflow {\n\n    // Define SRA input data channel\n    ch_sra_ids = Channel.fromList ( [\"SRR935090\", \"SRR935091\", \"SRR935092\"] )\n\n    // Define the workflow\n    GET_SRA_BY_ACCESSION (\n        ch_sra_ids\n    )\n}"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#anatomy-of-a-workflow-1",
    "href": "lectures/nextflow/nextflow.html#anatomy-of-a-workflow-1",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a workflow",
    "text": "Anatomy of a workflow\nworkflow {\n\n    // Define SRA input data channel\n    ch_sra_ids = Channel.fromList ( [\"SRR935090\", \"SRR935091\", \"SRR935092\"] )\n\n    // Define the workflow\n    GET_SRA_BY_ACCESSION (\n        ch_sra_ids\n    )\n    RUN_FASTQC (\n        GET_SRA_BY_ACCESSION.out\n    )\n}"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#anatomy-of-a-workflow-2",
    "href": "lectures/nextflow/nextflow.html#anatomy-of-a-workflow-2",
    "title": "Making reproducible workflows with ",
    "section": "Anatomy of a workflow",
    "text": "Anatomy of a workflow\nworkflow {\n\n    // Define SRA input data channel\n    ch_sra_ids = Channel.fromList ( [\"SRR935090\", \"SRR935091\", \"SRR935092\"] )\n\n    // Define the workflow\n    GET_SRA_BY_ACCESSION (\n        ch_sra_ids\n    )\n    RUN_FASTQC (\n        GET_SRA_BY_ACCESSION.out\n    )\n    RUN_MULTIQC (\n        RUN_FASTQC.out.collect()\n    )\n}"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#executing-nextflow",
    "href": "lectures/nextflow/nextflow.html#executing-nextflow",
    "title": "Making reproducible workflows with ",
    "section": "Executing Nextflow",
    "text": "Executing Nextflow\n\n\n\nExecute a workflow\n$ nextflow run main.nf\n\n\n\nRe-run using cached results\n$ nextflow run main.nf -resume\n\n\n\nExecute with a specific configuration file\n$ nextflow run main.nf -c nextflow.config\n\n\n\n\nSupply a custom parameter\n$ nextflow run main.nf --param \"value\"\n\n\n\nUse Docker or Apptainer\n$ nextflow run main.nf -with-docker\n$ nextflow run main.nf -with-apptainer\n\n\n\nUse a pre-defined configuration profile\n$ nextflow run main.nf -profile uppmax"
  },
  {
    "objectID": "lectures/nextflow/nextflow.html#snakemake-and-nextflow-differences",
    "href": "lectures/nextflow/nextflow.html#snakemake-and-nextflow-differences",
    "title": "Making reproducible workflows with ",
    "section": "Snakemake and Nextflow differences",
    "text": "Snakemake and Nextflow differences\n\n\n\n\n\n\n\n\n\nSnakemake\nNextflow\n\n\n\n\nLanguage\nPython\nGroovy\n\n\nData\nEverything is a file\nCan use both files and values\n\n\nExecution\nWorking directory\nEach job in its own directory\n\n\nPhilosophy\n“Pull”\n“Push”\n\n\nDry-runs\nYes\nNo\n\n\n\n\n\n\nQuestion: But, which one is the best?\nAnswer: Both - it’s mostly up to personal preference!"
  },
  {
    "objectID": "lectures/quarto/quarto.html#quarto-connects-code-with-results",
    "href": "lectures/quarto/quarto.html#quarto-connects-code-with-results",
    "title": "Making reports with ",
    "section": "Quarto connects code with results",
    "text": "Quarto connects code with results"
  },
  {
    "objectID": "lectures/quarto/quarto.html#quarto-connects-code-with-results-1",
    "href": "lectures/quarto/quarto.html#quarto-connects-code-with-results-1",
    "title": "Making reports with ",
    "section": "Quarto connects code with results",
    "text": "Quarto connects code with results\n\n\n---\ntitle: \"There's something about penguins\"\nauthor: \"John Doe, Joan Doe, Dyon Do\"\ndate: today\nformat:\n    html:\n        code-fold: true\n        warning: false\n---\n\n# Palmer penguins\n\n```{r Penguin figure}\n#| fig-width: 10\n#| fig-height: 5\nlibrary(\"ggplot2\")\nlibrary(\"palmerpenguins\")\ndata(penguins, package = \"palmerpenguins\")\nggplot(penguins, aes(x      = bill_length_mm,\n                     y      = body_mass_g,\n                     colour = species)) +\n    geom_point(size = 2) +\n    theme_bw() +\n    labs(x      = \"Bill length (mm)\",\n         y      = \"Body mass (g)\",\n         colour = \"Species\") +\n    scale_colour_manual(values = c(\"#c1dea0\",\n                                   \"#85be42\",\n                                   \"#425f21\"))\n```"
  },
  {
    "objectID": "lectures/quarto/quarto.html#quarto-connects-code-with-results-2",
    "href": "lectures/quarto/quarto.html#quarto-connects-code-with-results-2",
    "title": "Making reports with ",
    "section": "Quarto connects code with results",
    "text": "Quarto connects code with results\n\n\n---\ntitle: \"There's something about penguins\"\nauthor: \"John Doe, Joan Doe, Dyon Do\"\ndate: today\nformat:\n    html:\n        code-fold: true\n        warning: false\n---\n\n# Palmer penguins\n\n```{r Penguin figure}\n#| fig-width: 10\n#| fig-height: 5\nlibrary(\"ggplot2\")\nlibrary(\"palmerpenguins\")\ndata(penguins, package = \"palmerpenguins\")\nggplot(penguins, aes(x      = bill_length_mm,\n                     y      = body_mass_g,\n                     colour = species)) +\n    geom_point(size = 2) +\n    theme_bw() +\n    labs(x      = \"Bill length (mm)\",\n         y      = \"Body mass (g)\",\n         colour = \"Species\") +\n    scale_colour_manual(values = c(\"#c1dea0\",\n                                   \"#85be42\",\n                                   \"#425f21\"))\n```\n\nA YAML header:\n\nDefines document-wide options\nSpecifies the output format\nCan include several parameters\n\n\nMarkdown text:\n\nFreely add and format text using markdown\n\n\n\nCode chunks:\n\nEvaluate code and show its output\nSpecify global and/or local chunk options (e.g. figure dimensions)\nAlso works with other languages (e.g. Python)"
  },
  {
    "objectID": "lectures/quarto/quarto.html#rendering-quarto-documents",
    "href": "lectures/quarto/quarto.html#rendering-quarto-documents",
    "title": "Making reports with ",
    "section": "Rendering Quarto documents",
    "text": "Rendering Quarto documents\n\nRender from the command line:\nquarto render report.qmd\n\n\nRender to a specific format:\nquarto render report.qmd --to html\n\n\n\nMany IDEs like VS Code and RStudio also have buttons to render Quarto documents."
  },
  {
    "objectID": "lectures/quarto/quarto.html#output-formats",
    "href": "lectures/quarto/quarto.html#output-formats",
    "title": "Making reports with ",
    "section": "Output formats",
    "text": "Output formats\n\n\nReports and general documents (HTML, PDF, Jupyter Notebook, Microsoft Word)\nPresentations (reveal.js, PowerPoint, Beamer)\nInteractive documents (Observable, R Shiny)\nBooks, websites and blogs\nJournal articles\nYour own custom formats"
  },
  {
    "objectID": "lectures/quarto/quarto.html#presentations-with-quarto",
    "href": "lectures/quarto/quarto.html#presentations-with-quarto",
    "title": "Making reports with ",
    "section": "Presentations with Quarto",
    "text": "Presentations with Quarto\n\n\nlibrary(\"ggplot2\")\nlibrary(\"palmerpenguins\")\ndata(penguins, package = \"palmerpenguins\")\nggplot(penguins, aes(x      = bill_length_mm,\n                     y      = body_mass_g,\n                     colour = species)) +\n    geom_point(size = 2) +\n    theme_bw() +\n    labs(x = \"Bill length (mm)\",\n         y = \"Body mass (g)\") +\n    ggtitle(\"Penguin weight and bill length\") +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    scale_colour_manual(values = c(\"#c1dea0\", \"#85be42\", \"#425f21\"))"
  },
  {
    "objectID": "lectures/quarto/quarto.html#quarto-vs.-r-markdown",
    "href": "lectures/quarto/quarto.html#quarto-vs.-r-markdown",
    "title": "Making reports with ",
    "section": "Quarto vs. R Markdown",
    "text": "Quarto vs. R Markdown\n\n\nQuarto is a command line tool\nQuarto \\(\\thickapprox\\) R Markdown 2.0\nQuarto is language-agnostic (does not depend on R)\nQuarto has all functionality built-in (you don’t need to install another package to create e.g. presentations)\nThe Quarto format is similar to R Markdown\nQuarto can render R Markdown documents\nR Markdown will continue to be supported, but Quarto is the focus of new functionality and major development"
  },
  {
    "objectID": "pages/git.html",
    "href": "pages/git.html",
    "title": "Version control with Git",
    "section": "",
    "text": "Git is a widely used system (both in academia and industry) for version controlling files and collaborating on code. It is used to track changes in (text) files, thereby establishing a history of all edits made to each file, together with short messages about each change and information about who made it. Git is mainly run from the command line, but there are several tools that have implemented a graphical user interface to run Git commands.\nUsing version control for tracking your files, and edits to those, is an essential step in making your computational research reproducible. A typical Git workflow consists of:\n\nMaking distinct and related edits to one or several files\nCommitting those changes (i.e. telling Git to add those edits to the history, together with a message about what those changes involve)\nPushing the commit to a remote repository (i.e. syncing your local project directory with one in the cloud)\n\nThere are many benefits of using Git in your research project:\n\nYou are automatically forced into a more organized way of working, which is usually a first step towards reproducibility.\nIf you have made some changes to a file and realize that those were probably not a good idea after all, it is simple to view exactly what the changes were and revert them.\nIf there is more than one person involved in the project, Git makes it easy to collaborate by tracking all edits made by each person. It will also handle any potential conflicting edits.\nUsing a cloud-based repository hosting service (the one you push your commits to), like e.g. GitHub or Bitbucket, adds additional features, such as being able to discuss the project, comment on edits, or report issues.\nIf at some point your project will be published GitHub or Bitbucket (or similar) are excellent places to publicly distribute your code. Other researchers can then use Git to access the code needed for reproducing your results, in exactly the state it was when used for the publication.\nIf needed, you can host private repositories on GitHub and Bitbucket as well. This may be convenient during an ongoing research project, before it is publicly published.\n\nThese tutorials will walk you through the basics of using Git as a tool for reproducible research. The things covered in these tutorials are what you will be using most of the time in your day-to-day work with Git, but Git has many more advanced features that might be of use to you.\nThis tutorial depends on files from the course GitHub repo. Take a look at the setup for instructions on how to set it up if you haven’t done so already."
  },
  {
    "objectID": "pages/git.html#introduction",
    "href": "pages/git.html#introduction",
    "title": "Version control with Git",
    "section": "",
    "text": "Git is a widely used system (both in academia and industry) for version controlling files and collaborating on code. It is used to track changes in (text) files, thereby establishing a history of all edits made to each file, together with short messages about each change and information about who made it. Git is mainly run from the command line, but there are several tools that have implemented a graphical user interface to run Git commands.\nUsing version control for tracking your files, and edits to those, is an essential step in making your computational research reproducible. A typical Git workflow consists of:\n\nMaking distinct and related edits to one or several files\nCommitting those changes (i.e. telling Git to add those edits to the history, together with a message about what those changes involve)\nPushing the commit to a remote repository (i.e. syncing your local project directory with one in the cloud)\n\nThere are many benefits of using Git in your research project:\n\nYou are automatically forced into a more organized way of working, which is usually a first step towards reproducibility.\nIf you have made some changes to a file and realize that those were probably not a good idea after all, it is simple to view exactly what the changes were and revert them.\nIf there is more than one person involved in the project, Git makes it easy to collaborate by tracking all edits made by each person. It will also handle any potential conflicting edits.\nUsing a cloud-based repository hosting service (the one you push your commits to), like e.g. GitHub or Bitbucket, adds additional features, such as being able to discuss the project, comment on edits, or report issues.\nIf at some point your project will be published GitHub or Bitbucket (or similar) are excellent places to publicly distribute your code. Other researchers can then use Git to access the code needed for reproducing your results, in exactly the state it was when used for the publication.\nIf needed, you can host private repositories on GitHub and Bitbucket as well. This may be convenient during an ongoing research project, before it is publicly published.\n\nThese tutorials will walk you through the basics of using Git as a tool for reproducible research. The things covered in these tutorials are what you will be using most of the time in your day-to-day work with Git, but Git has many more advanced features that might be of use to you.\nThis tutorial depends on files from the course GitHub repo. Take a look at the setup for instructions on how to set it up if you haven’t done so already."
  },
  {
    "objectID": "pages/git.html#creating-repositories",
    "href": "pages/git.html#creating-repositories",
    "title": "Version control with Git",
    "section": "2 Creating repositories",
    "text": "2 Creating repositories\nIn order to create a new Git repository, we first need a directory to track. For this tutorial, go ahead and create a directory called git_tutorial, then navigate into it.\n\n\n\n\n\n\nWarning\n\n\n\nThe directory should not be within the workshop-reproducible-research directory, since this is itself a Git-tracked directory.\n\n\nOnce we are inside the desired directory, we can initialise Git with the following command:\ngit init\nThe directory is now a version-tracked directory. How can you know? Run the command git status, which will probably return something like this:\nOn branch main\n\nNo commits yet\n\nnothing to commit (create/copy files and use \"git add\" to track)\n\n\n\n\n\n\nTip\n\n\n\nIf you try to run git status in a non-Git directory, it will say that it is not a git repository. The way this works is that Git adds a hidden directory .git/ in the root of a Git tracked directory (run ls -a to see it). This hidden directory contains all information and settings Git needs in order to run and version track your files. This also means that your Git-tracked directory is self-contained, i.e. you can simply delete it and everything that has to do with Git in connection to that directory will be gone.\n\n\nThe text nothing to commit (create/copy files and use \"git add\" to track) tells us that while we are inside a directory that Git is currently tracking, there are currently no files being tracked; let’s add some!\nCopy the following files from the workshop-reproducible-research/tutorials/git directory into your git_tutorial directory:\n\nDockerfile\nSnakefile\nconfig.yml\nenvironment.yml\n\nOnce you have done that, run git status again. It will tell you that there are files in the directory that are not version tracked by Git.\n\n\n\n\n\n\nNote\n\n\n\nFor the purpose of this tutorial, the exact contents of the files you just copied are not important. But you will probably recognize many of them, as they are all files used in the MRSA case study described in the introduction to the tutorials. The details of what these files do are described in their respective sessions later in the course, but we provide a brief overview here:\n\nThe environment.yml file contains the Conda environment with all the software used in the analysis (see the Conda tutorial).\nThe Snakefile and config.yml are both used to define the Snakemake workflow, that we’ll go through in the Snakemake tutorial.\nThe Dockerfile contains the recipe for making a Docker container for the analysis, which will be covered in detail in the Container tutorial.\n\n\n\n\n\n\n\n\n\nQuick recap\n\n\n\nWe have used two git commands this far:\n\ngit init tells Git to track the current directory.\ngit status is a command you should use a lot. It will tell you, amongst other things, the status of your Git clone in relation to the online remote repository."
  },
  {
    "objectID": "pages/git.html#adding-and-committing-files",
    "href": "pages/git.html#adding-and-committing-files",
    "title": "Version control with Git",
    "section": "3 Adding and committing files",
    "text": "3 Adding and committing files\nWe will now commit the untracked files. A commit is essentially a set of changes to a set of files. Preferably, the changes making out a commit should be related to something, e.g. a specific bug fix or a new feature.\n\nOur first commit will be to add the copied files to the repository. Run the following (as suggested by git status):\n\ngit add Dockerfile Snakefile\n\nRun git status again! See that we have added Dockerfile and Snakefile to our upcoming commit (listed under “Changes to be committed”). This is called the staging area, and the files there are staged to be committed.\nWe might as well commit all files in one go! Use git add on the remaining files as well:\n\ngit add config.yml environment.yml\n\nRun git status and see that all files are in the staging area, and that no files are listed as untracked.\nWe are now ready to commit! Run the following:\n\ngit commit -m \"Add initial files\"\nThe -m option adds a commit message. This should be a short description of what the commit contains.\n\n\n\n\n\n\nGood commit messages\n\n\n\nWriting informative and succinct commit messages can be tricky when you’re just starting out. Here are some general guidelines that can help you write good commit messages from the start:\n\nSeparate subject from body with a blank line\nLimit the subject line to 50 characters\nCapitalize the subject line\nDo not end the subject line with a period\nUse the imperative mood in the subject line\nWrap the body at 72 characters\nUse the body to explain what and why vs. how\n\nIn the command above we just added a short subject line (“Add initial files”). It is capitalized, less than 50 characters, does not end with a period, and uses imperative mood (Add!). It is possible to add a descriptive body text as well, as hinted by the points above. This is easiest done in a text editor. If you run git commit without the -m flag, Git will open the default terminal text editor (which can be configured with the core.editor variable) where you can write a longer commit message and body. If you want to read more about the motivation for these points, please see this website.\n\n\n\nRun git status again. It should tell you “nothing to commit, working directory clean”.\n\nWhat have we done, so far? We had some files in our working directory that we added to the Git staging area, which we subsequently committed to our Git repository. A schematic overview of this process can be seen in the following figure:\n\nLet’s repeat this process by editing a file!\n\nOpen up environment.yml in your favourite editor, and change the version of Bowtie2 to a different value, e.g. bowtie2=2.2.4.\nRun git status. It will tell you that there are modifications in one file (environment.yml) compared to the previous commit. This is nice! We don’t have to keep track of which files we have edited, Git will do that for us.\nRun git diff environment.yml. This will show you the changes made to the file. A - means a deleted line, a + means an added line. There are also shown a few lines before and after the changes, to put them in context.\nLet’s edit another file! Open config.yml and change the line genome_id: NCTC8325 to genome_id: ST398. Run git status. Run git diff. If we don’t specify a file, it will show all changes made in any file, compared to the previous commit. Do you see your changes?\nOkay, we made our changes. Let’s commit them! Run:\n\ngit add config.yml environment.yml\nThis will add both our files to the staging area at the same time. Run git status and see that the changes in both config.yml and environment.yml are ready to be committed.\n\n3.1 Unstaging files\nBut wait a minute! Shouldn’t each commit optimally be a conceptual unit of change? Here we have one change to the genome ID used for an analysis and one change where another software version is specified: these should probably be separate. We thus want to make two commits, one for each change.\n\nLet’s remove environment.yml from the staging area.\n\ngit restore --staged environment.yml\n\n\n\n\n\n\nNote\n\n\n\nPlease note the use of the --staged flag here, which simply removes the specified file(s) from the staging area without changing the file contents. Using the restore command without this flag will not only remove the file from the staging area, but also restore the file to the state it was in the last commit, which is not what we want here.\n\n\n\nRun git status again. See that now only config.yml is staged for being committed, whereas the changes in environment.yml are tracked by Git, but not ready to be committed.\nCommit the changes in config.yml:\n\ngit commit -m \"Change to ST398 for alignment\"\n\nAdd and commit the changes in environment.yml:\n\ngit status\ngit add environment.yml\ngit status\ngit commit -m \"Change Bowtie2 version\"\ngit status\nYou don’t have to run git status between each command, but it can be useful in the beginning while learning what each command does.\nAs you can see, each commit is a point in history. The more often you commit, and the more specific you keep your commits, the better (more fine-grained) history and version tracking you will have of your files.\n\n\n3.2 Deleting files\n\nWe can also try to delete a file:\n\nrm Dockerfile\n\nRun git status. As you can see, Git tells us that the file is deleted, but that the deletion is not committed. In the same way as we commit edits to files, we need to commit a deletion of a file:\n\ngit add Dockerfile\ngit status\ngit commit -m \"Remove Dockerfile\"\ngit status\nHere we used rm Dockerfile to delete the file and git add Dockerfile to stage the deletion. You can also use git rm Dockerfile to do both these operations in one step.\n\n\n3.3 Browsing the history\n\nTo see a history of our changes so far, run:\n\ngit log\n\n\n\n\n\n\nNote\n\n\n\nSince Git keeps track of changes in text, e.g. code and text-based documentation, there are some files which you should not commit. Examples of such files are file formats that are not text-based, e.g. Microsoft Word/Excel files or PDFs - although one might sometimes want to track one of these files regardless, such as when you have a static PDF report you received from a sequencing platform that’s never going to change. Other files you shouldn’t track are vary large text files, e.g. those larger than 50 MB.\n\n\n\n\n\n\n\n\nQuick recap\n\n\n\nWe added four important Git commands to our repertoire:\n\ngit add adds a file to the staging area\ngit commit commits the changes we have staged\ngit restore --staged to remove files from the staging area\ngit rm is shorthand for rm &lt;file&gt;; git add &lt;file&gt;\ngit log shows us the commit history"
  },
  {
    "objectID": "pages/git.html#ignoring-files",
    "href": "pages/git.html#ignoring-files",
    "title": "Version control with Git",
    "section": "4 Ignoring files",
    "text": "4 Ignoring files\nGit is aware of all files within the repository. However, it is not uncommon to have files that we don’t want Git to track. For instance, our analysis might produce several intermediate files and results. We typically don’t track such files. Rather, we want to track the actual code and other related files (e.g. configuration files) that produce the intermediate and result files, given the raw input data.\n\nLet’s make some mock result files. These are some of the files that would have been generated by the Snakemake workflow if it was run.\n\nmkdir -p results/multiqc\ntouch results/multiqc/multiqc_general_stats.txt\ntouch results/supplementary.html\ntouch log.tmp\n\nRun git status. You will see that Git tells you that you have untracked files. However, we don’t want Git to track these files anyway. To tell Git what files to ignore we use a file called .gitignore. Let’s create it:\n\ntouch .gitignore\n\nOpen the .gitignore file in a text editor and add the following lines to it:\n\n# Ignore these directories:\nresults/\n\n# Ignore temporary files:\n*.tmp\n\nRun git status again. Now there is no mention of the results directory or the log.tmp file. Notice that we can use wildcards (*) to ignore files with a given pattern, e.g. a specific file extension.\nSometimes you want to ignore all files in a directory with one or two exceptions. For example, you don’t want to track all your huge raw data files, but there may be a smaller data file that you do want to track, e.g. metadata or a list of barcodes used in your experiment. Let’s add some mock data:\n\nmkdir data\ntouch data/huge.fastq.gz\ntouch data/metadata.txt\n\nGit allows you to ignore all files using the aforementioned wildcard, but then exclude certain files from that ignore command. Open the .gitignore file again and add the following:\n\n# Ignore all files in the data/ directory\ndata/*\n\n# Exclude the metadata file by prefixing it with an exclamation mark\n!data/metadata.txt\n\nFinish up by adding the .gitignore and data/metadata.txt files to the staging area and committing them:\n\ngit add .gitignore\ngit commit -m \"Add .gitignore file\"\ngit add data/metadata.txt\ngit commit -m \"Add metadata file\"\n\n\n\n\n\n\nTip\n\n\n\nIt is common for certain programming languages or text editors to leave e.g. swap files or hidden data files in the working directory, which you don’t want to track using Git. Instead of manually adding these to every single project you have, you can use the .gitignore_global file, which should be placed in your home directory. It works exactly like a normal gitignore file, but is applied to all Git repositories that you are using on your machine. Some common file extensions that might be put in the global gitignore are .DS_Store if you’re working on a Mac or .swp if you’re coding in (Neo)Vim. To configure git to use the .gitignore_global file you can run git config --global core.excludesfile ~/.gitignore_global.\n\n\n\n\n\n\n\n\nQuick recap\n\n\n\nWe now learned how to ignore certain files and directories:\n\nThe .gitignore file controls which files and directories Git should ignore, if any.\nSpecific files can be excluded from ignored directories using the exclamation mark (!) prefix."
  },
  {
    "objectID": "pages/git.html#branches",
    "href": "pages/git.html#branches",
    "title": "Version control with Git",
    "section": "5 Branches",
    "text": "5 Branches\nOne of the most useful features of Git is called branching. Branching allows you to diverge from the main line of work and edit or update your code and files (e.g. to test out a new analysis or some experimental feature) without affecting your main work. If the work you did in the branch turns out to be useful you can merge that back into your main branch. On the other hand, if the work didn’t turn out as planned, you can simply delete the branch and continue where you left off in your main line of work. Another use case for branching is when you are working in a project with multiple people. Branching can be a way of compartmentalizing your team’s work on different parts of the project and enables merging back into the main branch in a controlled fashion; we will learn more about this in the section about working remotely.\n\nLet’s start trying out branching! We can see the current branch by running:\n\ngit branch\nThis tells us that there is only the main branch at the moment.\n\n\n\n\n\n\nMain and Master\n\n\n\nIf your branch is called master instead of main that’s perfectly fine as well, but do check out the Git section of the pre-course setup for more details about the choice of default branch names.\n\n\n\nLet’s make a new branch:\n\ngit branch test_alignment\n\nRun git branch again to see the available branches. Do you note which one is selected as the active branch?\nLet’s move to our newly created branch using the switch command:\n\ngit switch test_alignment\n\n\n\n\n\n\nTip\n\n\n\nYou can create and switch to a new branch in one line with git switch -c branch_name (or --create).\n\n\nLet’s add some changes to our new branch! We’ll use this to try out a different set of parameters on the sequence alignment step of the case study project.\n\nEdit the Snakefile so that the shell command of the align_to_genome rule looks like this (add the --very-sensitive-local option):\n\nbowtie2 --very-sensitive-local -x results/bowtie2/{config[genome_id]} -U {input.fastq} &gt; {output} 2&gt;{log}\n\nAdd and commit the change!\nTo get a visual view of your branches and commits you can use the command:\n\ngit log --graph --all --oneline\nIt is often useful to see what differences exist between branches. You can use the diff command for this:\ngit diff main\nThis shows the difference between the active branch (test_alignment) and main on a line-per-line basis. Do you see which lines have changed between test_alignment and main branches?\n\n\n\n\n\n\nTip\n\n\n\nWe can also add the --color-words flag to git diff, which instead displays the difference on a word-per-word basis rather than line-per-line.\n\n\n\n\n\n\n\n\nNote\n\n\n\nGit is constantly evolving, along with some of its commands. The checkout command was previously used for switching between branches, but this functionality now has the dedicated (and clearer) switch command for this. If you’ve previously learned using checkout instead you can keep doing that without any issues, as the checkout command itself hasn’t changed.\n\n\nNow, let’s assume that we have tested our code and the alignment analysis is run successfully with our new parameters. We thus want to merge our work into the main branch. It is good to start with checking the differences between branches (as we just did) so that we know what we will merge.\n\nSwitch to the branch you want to merge into, i.e. main:\n\ngit switch main\n\nTo merge, run the following code:\n\ngit merge test_alignment\nRun git log --graph --all --oneline again to see how the merge commit brings back the changes made in test_alignment to main.\n\n\n\n\n\n\nTip\n\n\n\nIf working on different features or parts of an analysis on different branches, and at the same time maintaining a working main branch for the stable code, it is convenient to periodically merge the changes made to main into relevant branches (i.e. the opposite to what we did above). That way, you keep your experimental branches up-to-date with the newest changes and make them easier to merge into main when time comes.\n\n\n\nIf we do not want to do more work in test_alignment we can delete that branch:\n\ngit branch -d test_alignment\n\nRun git log --graph --all --oneline again. Note that the commits and the graph history are still there? A branch is simply a pointer to a specific commit, and that pointer has been removed.\n\n\n\n\n\n\n\nTip\n\n\n\nThere are many types of so-called “branching models”, each with varying degrees of complexity depending on the developer’s needs and the number of collaborators. While there certainly isn’t a single branching model that can be considered to be the “best”, it is very often most useful to keep it simple. An example of a simple and functional model is to have a main branch that is always working (i.e. can successfully run all your code and without known bugs) and develop new code on feature branches (one new feature per branch). Feature branches are short-lived, meaning that they are deleted once they are merged into main.\n\n\n\n\n\n\n\n\nQuick recap\n\n\n\nWe have now learned how to divide our work into branches and how to manage them:\n\ngit branch &lt;branch&gt; creates a new branch.\ngit switch &lt;branch&gt; moves the repository to the state in which the specified branch is currently in.\ngit merge &lt;branch&gt; merges the specified branch into the current one."
  },
  {
    "objectID": "pages/git.html#tags",
    "href": "pages/git.html#tags",
    "title": "Version control with Git",
    "section": "6 Tags",
    "text": "6 Tags\nGit allows us to tag commits, i.e. give names to specific points in the history of our project. This can be particularly important for reproducible research, but also for development projects that want to highlight specific versions of a software. A tag can be, for example, the version of the repository that was used for the manuscript submission, the version used during resubmission, and, most importantly, the version used for the final publication. The first two examples are mainly useful internally, but the latter is essential for other researchers to be able to rerun your published analysis.\n\nLet’s assume that the status of the repository as it is now is ready for a submission to a journal. It may for example contain the scripts that were used to generate the manuscript figures. Let’s add a tag:\n\ngit tag \"submission1\"\n\nWe can now list all the tags available in the current repository:\n\ngit tag\n\n\n\n\n\n\nTip\n\n\n\nYou can use the flag -a or --annotate to give more detailed information about a specific tag, similar to a commit message. This can be quite useful when there are many changes that happened, in that it allows you to summarise them. You can, for example, do git tag -a submission1 -m \"Annotation for tag submission1\" to write the annotation along with the command (similar to the -m flag for committing) or just git tag -a submission1 to write the annotation with your default editor. To list all your tags along with their annotations you can use e.g. git tag -n10 (which will list the first 10 lines of each tag’s annotation).\n\n\n\nLet’s assume we now got comments from the reviewers, and by fixing those we had to update our code. Open config.yml and change the line max_reads: 25000 to max_reads: 50000. Commit and tag the changes:\n\ngit add config.yml\ngit commit -m \"Increase number of reads\"\ngit tag \"revision-1\"\n\nNow let’s say that the reviewers were happy and the manuscript was accepted for publication. Let’s immediately add a tag:\n\ngit tag \"publication\"\n\nA good thing about using tags is that you can easily switch between versions of your code. Let’s move to the first submission version:\n\ngit switch -d submission1\nWhen switching between tags you have to use the -d (or --detach) flag to the switch command. This is because the switch command only switches between branches as default; switching between tags requires us to be in a detached state. This means that we’re not actually on a branch, but rather at a specific point in the Git history without a branch.\n\nOpen config.yml and note that the max_reads variable is 25000! To go back to the latest version, run:\n\ngit switch main\n\nOpen config.yml and see that the value is now 50000.\n\n\n\n\n\n\n\nTip\n\n\n\nYou can also see the difference between tags in the same way as for branches and commits using e.g. git diff &lt;tag1&gt; &lt;tag2&gt;.\n\n\nAt this point could run git log --oneline --decorate to get a condensed commit history, where you should also be able to see the tagged commits.\n\n\n\n\n\n\nQuick recap\n\n\n\nWe have now learned how to tag important commits:\n\ngit tag adds a tag to a commit.\ngit switch -d moves between tags in a similar fashion as between branches."
  },
  {
    "objectID": "pages/git.html#working-remotely",
    "href": "pages/git.html#working-remotely",
    "title": "Version control with Git",
    "section": "7 Working remotely",
    "text": "7 Working remotely\nSo far we’ve only been working on files present on our own computer, i.e. locally. While Git is an amazing tool for reproducibility even if you’re working alone, it really starts to shine in collaborative work. This entails working with remote repositories, i.e. repositories that are stored somewhere online; some of the most common places to store your repositories are GitHub, BitBucket and GitLab. GitHub is the most popular of these, and is what we’ll be using for this tutorial.\nAn important thing to keep in mind here is the difference between Git (the version control system) and online hosting of Git repositories (such as GitHub): the former is the core of keeping track of your code’s history, while the latter is how to store and share that history with others.\n\n7.1 Create a remote repository\nLog in to your GitHub account and press the New button:\n\nMake sure you are listed as the owner\nAdd a repository name, e.g. git_tutorial\nYou can keep the repo private or make it public, as you wish\nSkip including a README, a .gitignore and licence\n\n\n\n\nYou will now be redirected to the repository page which will list several ways for you to start adding content (files) to the repository. What we will do is to connect the local repository we’ve been working on so far to the remote GitHub server using SSH:\n\nAdd a remote SSH address to your local repository (make sure you change user to your GitHub username and git_tutorial to your repository name):\n\ngit remote add origin git@github.com:user/git_tutorial.git\n\nRun git remote -v. This will show you what remote location is connected to your local Git clone. The short name of the default remote is usually “origin” by convention.\n\n\n\n\n\n\n\nNote\n\n\n\nMake sure you’ve used an SSH address (i.e. starting with git@github.com rather than an HTTPS address (starting with https://github.com)!\n\n\n\nWe have not yet synced the local and remote repositories, though, we’ve simply connected them. Let’s sync them now:\n\ngit push origin main\nThe push command sends our local history of the main branch to the same branch on the remote (origin). Our Git repository is now stored on GitHub!\n\nRun git status. This should tell you that:\n\nOn branch main\nnothing to commit, working tree clean\nYou always need to specify git push origin main by default, but you can circumvent this by telling Git that you always want to push to origin/main when you’re on your local main branch. To do this, use the command git branch --set-upstream-to origin/main. Try it out now.\n\nNow run git-status again. You should see that now git additionally tells you that your local branch is up to date with the remote branch.\n\nIf you go to the repository’s GitHub page you should now be able to see all your files and your code there! It should look something like this:\n\n\n\nYou can see a lot of things there, such as each file and the latest commit that changed them, the repository’s branches and a message from GitHub at the bottom: “Help people interested in this repository understand your project by adding a README.” This refers to GitHub’s built-in functionality of automatically rendering any markdown document named README or README.md in the repository’s root directory and displaying it along with what you can already see. Let’s try it out!\n\nLet’s create a README.md file and fill it with the following text:\n\n# A Git tutorial\n\nThis repository contains tutorial information related to the **NBIS/ELIXIR** course\n_Tools for Reproducible Research_, specifically the session on using the `git`\nsoftware for version control.\n\n### Links\n\nYou can find the latest stable version of the Git tutorial for the course\n[here](https://uppsala.instructure.com/courses/87979/pages/git-7-working-remotely?module_item_id=890886).\n\n\n\n\n\n\nThe Markdown format\n\n\n\nIf you haven’t seen this format before you can learn more about it at the markdown page.\n\n\n\nAdd, commit and push these changes to GitHub.\n\ngit add README.md\ngit commit -m \"Add README.md\"\ngit push origin main\nYou should now be able to see the rendered markdown document in your GitHub repository. It is important to add README-files to your repositories so that they are better documented and more easily understood by others and, more likely, your future self. In fact, documentation is an important part of reproducible research! While the tools that you are introduced to by this course are all directly related to making science reproducible, you will also need good documentation. Make it a habit of always adding README-files for your repositories, fully explaining the ideas and rationale behind the project. You can even add README-files to sub-directories as well, giving you the opportunity to go more in-depth where you so desire.\n\n\n\n\n\n\nQuick recap\n\n\n\nWe learned how to connect local Git repositories to remote locations such as GitHub and how to upload commits using git push. We also learned the basics of markdown and how it can be used to document Git repositories.\n\n\n\n\n7.2 Browsing GitHub\nGitHub and the rest of the websites that offer remote hosting of git repositories all have numerous features, which can be somewhat difficult to navigate in the beginning. We here go through some of the basics of what you can do with GitHub.\n\nGo to your GitHub repository in your browser again and click on Code to the left. Click on config.yml. You will see the contents of the file. Notice that it is the latest version, where we previously changed the genome_id variable:\n\n\n\n\n\nClick on History. You will see an overview of the commits involving changes made to this file:\n\n\n\n\n\nClick on the Change to ST398 for alignment commit. You will see the changes made to config.yml file compared to the previous commit.\n\n\n\n\n\nGo back to the repository’s main page and click on the commit tracker on the right above the list of files, which will give you an overview of all commits made. Clicking on a specific commit lets you see the changes introduced by that commit. Click on the commit that was the initial commit, where we added all the files.\n\n\n\n\nYou will now see the files as they were when we first added them. Specifically you can see that the Dockerfile is back, even though we deleted it! Click on the Code tab to the left to return to the overview of the latest repository version.\n\n\n7.3 Working with remote repositories\nWhile remote repositories are extremely useful as backups and for collaborating with others, that’s not their only use: remotes also help when you are working from different computers, a computer cluster or a cloud service.\n\nLet’s pretend that you want to work on this repository from a different computer. First, create a different directory (e.g. git_remote_tutorial) in a separate location that is not already tracked by Git and cd into it. Now we can download the repository we just uploaded using the following:\n\ngit clone git@github.com:user/git_tutorial.git .\nAgain, make sure to replace user with your GitHub user name.\nNotice the dot at the end of the command above, which will put the clone into the current directory, instead of creating a new directory with the same name as the remote repository. You will see that all your files are here, identical to the original git_tutorial repository!\n\nSince you already gave the address to Git when you cloned the repository, you don’t have to add it manually as before. Verify this with git remote -v.\nLet’s say that we now want to change the multiqc software to an earlier version: open the environment.yml file in the second local repo and change multiqc=1.14 to multiqc=1.7; add and commit the change.\nWe can now use push again to sync our remote repository with the new local changes. Refresh your web page again and see that the changes have taken effect.\n\nSince we have now updated the remote repository with code that came from the second local repository, the first local repository is now outdated. We thus need to update the first local repo with the new changes. This can be done with the pull command.\n\ncd back into the first local repository (e.g. git_tutorial) and run the git pull command. This will download the newest changes from the remote repository and merge them locally automatically.\nCheck that everything is up-to-date with git status.\n\nAnother command is git fetch, which will download remote changes without merging them. This can be useful when you want to see if there are any remote changes that you may want to merge, without actually doing it, such as in a collaborative setting. In fact, git pull in its default mode is just a shorthand for git fetch followed by git merge FETCH_HEAD (where FETCH_HEAD points to the tip of the branch that was just fetched).\nThat’s quite a few concepts and commands you’ve just learnt! It can be a bit hard to keep track of everything and the connections between local and remote Git repositories and how you work with them, but hopefully the following figure will give you a short visual summary:\n\n\n\n\n\n\n\nQuick recap\n\n\n\nWe have learned the difference between local and remote copies of git repositories and how to sync them:\n\ngit push uploads commits to a remote repository\ngit pull downloads commits from a remote repository and merges them to the local branch\ngit fetch downloads commits from a remote repository without merging them to the local branch\ngit clone makes a local copy of a remote repository\n\n\n\n\n\n7.4 Remote branches\nRemote branches work much in the same way a local branches, but you have to push them separately; you might have noticed that GitHub only listed our repository as having one branch (you can see this by going to the Code tab). This is because we only pushed our main branch to the remote. Let’s create a new local branch and add some changes that we’ll push as a separate branch to our remote - you should do this in the original git_tutorial repository, so make sure you’re in that directory.\n\nCreate a new branch named trimming and add the --trim5 5 flag to the Bowtie2-command part of the Snakefile, which should now look like this:\n\nbowtie2 --trim5 5 --very-sensitive-local -x results/bowtie2/{config[genome_id]} -U {input.fastq} &gt; {output} 2&gt;{log}\n\nAdd and commit the change to your local repository.\nInstead of doing what we previously did, i.e. merge the trimming branch into the main branch, we’ll push trimming straight to our remote:\n\ngit push origin trimming\n\nGo the repository at GitHub and see if the new branch has appeared. Just above the file listing click the Branch drop-down and select the new branch to view it. Can you see the difference in the Snakefile depending on which branch you choose?\n\nWe now have two branches both locally and remotely: main and trimming. We can continue working on our trimming branch until we’re satisfied (all the while pushing to the remote branch with the same name), at which point we want to merge it into main.\n\nSwitch to your local main branch and merge it with the trimming branch.\nPush your main branch to your remote and subsequently delete your local trimming branch.\n\nThe above command only deleted the local branch. If you want to remove the branch from the remote repository as well, run:\ngit push origin --delete trimming\n\n\n\n\n\n\nQuick recap\n\n\n\nWe learned how to push local branches to a remote with git push origin &lt;branch&gt; and how to delete remote branches with git push origin --delete &lt;branch&gt;.\n\n\n\n\n7.5 Sharing tags\nYour local repository tags are not included when you do a normal push. To push tags to the remote you need to supply the --tags flag to the git push command:\ngit push --tags\n\nGo to the repository overview page on GitHub. You will see that the repository now has three tags! If you click on Tags you will be given an overview of the existing tags for your repository - if you click Releases you will see more or less the same information. Confusing? Well, a tag is a Git concept while a release is a GitHub concept that is based on Git tags. Releases add some extra features that can be useful for distributing software and are done manually from the repository’s GitHub page.\nClick on one of the tags. Here users can download a compressed file containing the repository at the version specified by the tags.\n\n\n\n\nAlternatively, Git users who want to reproduce your analysis with the code used for the publication can clone the GitHub repository and then run git switch -d publication.\n\n\n\n\n\n\nQuick recap\n\n\n\nWe learned how to push Git tags to a remote by using the --tags flag."
  },
  {
    "objectID": "pages/git.html#conflicts",
    "href": "pages/git.html#conflicts",
    "title": "Version control with Git",
    "section": "8 Conflicts",
    "text": "8 Conflicts\nIt is not uncommon to run into conflicts when you are trying to merge separate branches, and it’s even more common when you’re working in a collaborative setting with remote repositories. It’ll happen sooner or later, even if you’re only working locally, so it’s important to know how to deal with them! We’ll now introduce a conflict on purpose, which we can then solve.\n\nRemember that we have two separate local copies of the same repository? Let’s go into the first one, git_tutorial, and change the MultiQC version in the environment.yml file:\n\nmultiqc=1.8\n\nAdd, commit and push your change to the remote.\n\nNow we have a change in our remote and one of our local copies, but not in the other. This could happen if a collaborator of yours committed a change and pushed it to GitHub. Let’s create a conflict!\n\nMove into your other local repository, git_remote_tutorial, which doesn’t have the new change. Run git status. Notice that Git says: “Your branch is up-to-date with ‘origin/main’.”. We know that this is not true, but this local clone is not yet aware of the remote changes.\nLet’s change the environment.yml file in this local repository as well, but to version 1.6, instead! It may be the case that your collaborator thought it was good to use MultiQC version 1.8, whereas you thought it would be better to use MultiQC version 1.6, but neither of you communicated that to the other.\nAdd and commit your change and try to push the commit, which should give you an error message that looks like this:\n\n ! [rejected]        main -&gt; main (fetch first)\nerror: failed to push some refs to 'https://github.com/user/git_tutorial.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first integrate the remote changes\nhint: (e.g., 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\nThis error message is thankfully quite informative in regards to what is going on and what might be done about it. In essence it will not allow you to push to the remote since there are conflicting changes made to it.\n\nLet’s download the changes made to the remote, but without trying to merge them directly. This can be done using the following command:\n\ngit fetch\n\n\n\n\n\n\nNote\n\n\n\nThe fetch command is very similar to pull in that it downloads remote changes that are not present locally, but differs in that it doesn’t try to merge them locally; pull both downloads and merges (unless there’s a conflict, in which case it will tell you so and raise an error like the one above). You can thus skip fetch and just do pull straight away, if you prefer.\n\n\n\nNow run git status. Unlike before, our local Git clone now is aware of the latest changes pushed to the remote. It will tell you something along the lines: “Your branch and ‘origin/main’ have diverged, and have 1 and 1 different commit each, respectively.”.\nWe can now run the following to see what the difference is between the current state of our local clone and the main branch on the remote origin:\n\ngit diff origin/main\n\nNow let’s try to integrate the remote changes with our local changes and get up to sync with the remote:\n\ngit merge\nUnsurprisingly, the git merge command resulted in a conflict. Git tells us about this and suggests that we should fix the conflicts and commit that.\n\nAs always, run git status to get an overview: you will see that you have so-called unmerged paths and that the conflicting file is environment.yml, since both modified the same line in this file. To fix a conflict, open the affected file in a text editor. You will see that it now looks something like this:\n\nname: git-env\nchannels:\n  - conda-forge\n  - bioconda\n  - r\ndependencies:\n  - python=3.10.10\n  - fastqc=0.11.9\n  - seqtk=1.3\n  - snakemake=7.25.0\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n  - multiqc=1.6\n=======\n  - multiqc=1.8\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; refs/remotes/origin/main\n  - bowtie2=2.5.1\n  - tbb=2021.8.0\n  - samtools=1.16\n  - subread=2.0.3\n  - bedtools=2.30.0\n  - r-base=4.1.3\n  - r-ggplot2=3.4.2\n  - r-reshape2=1.4.4\n  - r-stringi=1.7.12\n  - r-pheatmap=1.0.12\n  - r-r.utils=2.12.2\n  - bioconductor-rtracklayer=1.54.0\n  - bioconductor-geoquery=2.62.0\n  - wget\n  - graphviz\n  - xorg-libxrender\n  - xorg-libxpm\nThe part between &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD and ======= is your local version, and the part between ======= and &gt;&gt;&gt;&gt;&gt;&gt;&gt; refs/remotes/origin/main is the one added to the remote and which caused the conflict when you tried to merge those changes to your local repository. It is now up to you to decide which version to keep, or to change it to a third alternative.\n\nLet’s say that you are confident that it is better to run MultiQC 1.6 rather than 1.8. Edit the file so that it looks like you want it to, i.e. remove the lines added by Git and delete the line with multiqc=1.8. The final file should look like this:\n\nname: git-env\nchannels:\n  - conda-forge\n  - bioconda\n  - r\ndependencies:\n  - python=3.10.10\n  - fastqc=0.11.9\n  - seqtk=1.3\n  - snakemake=7.25.0\n  - multiqc=1.6\n  - bowtie2=2.5.1\n  - tbb=2021.8.0\n  - samtools=1.16\n  - subread=2.0.3\n  - bedtools=2.30.0\n  - r-base=4.1.3\n  - r-ggplot2=3.4.2\n  - r-reshape2=1.4.4\n  - r-stringi=1.7.12\n  - r-pheatmap=1.0.12\n  - r-r.utils=2.12.2\n  - bioconductor-rtracklayer=1.54.0\n  - bioconductor-geoquery=2.62.0\n  - wget\n  - graphviz\n  - xorg-libxrender\n  - xorg-libxpm\n\nRun git status again. Notice that it says use \"git add &lt;file&gt;...\" to mark   resolution? Let’s do that!\n\ngit add environment.yml\n\nRun git status again! It will now tell us: All conflicts fixed but you are   still merging. (use \"git commit\" to conclude merge). So, you probably guessed it, run:\n\ngit commit -m \"Merge and set MultiQC to v1.6\"\n\nFinally, push these changes to GitHub:\n\ngit push\n\nGo to GitHub in the browser and click the commit tracker again. You will see a list of commits including where MultiQC was first changed to version 1.7 from our previous work, then to 1.8, 1.6 and, finally, followed by a merge where the version was set to 1.6.\n\n\n\n\n\n\n\nNote\n\n\n\nWhile the example we’ve used here is from a collaborative setting, conflicts also arise when you are working alone. They usually happen when you have several feature branches that you want to merge into main and you’ve forgot to keep all branches up-to-date with each other.\n\n\n\n\n\n\n\n\nQuick recap\n\n\n\nWe learned about how conflicting commits can happen and how to deal with them by inspecting the affected files and looking for the source of the conflict."
  },
  {
    "objectID": "pages/git.html#extra-material",
    "href": "pages/git.html#extra-material",
    "title": "Version control with Git",
    "section": "9 Extra material",
    "text": "9 Extra material\nThe following extra material contains some more advanced things you can do with Git and the command line in general, which is not part of the main course materials. All the essential skills of Git are covered by the previous sections; the material here should be considered tips and tricks from people who use Git every day. You thus don’t need to use these things unless you want to, and you can even skip this part of the lesson if you like!\nIf you are interested in learning more about Git in general, here are some reading tips for you:\n\nGit cheat-sheet\nA simple Git guide\nResources to learn Git\nGit reference manual\n\n\n9.1 Forking\nWhen you want to work on an Open Source project that is available on e.g. GitHub, you usually don’t have permission to directly push code to the project’s repository - this is so that the project’s maintainers are the only ones that can directly change anything in their codebase. How do you then contribute to projects that don’t allow you to push your code to their repository? Simple: use forking!\nForking is when you make your own copy of a repository on your GitHub account, which you will then have permissions to change as you see fit. You can then create pull requests from your fork to the original repository, rather than pushing code to a new branch and making a pull request from that. Working with forks just adds an additional step to the whole workflow: instead of being “clone; code and commit changes on a new branch; push branch to remote; pull request from branch” it becomes “fork; clone; code and commit changes; push code to fork; pull request from fork”.\nYou might also want to do a fork of a project simply because you want to have your own copy of it as well, without ever having the intention of changing it. This is, of course, perfectly fine as well, but do keep in mind that developers are usually quite happy to incorporate new changes from contributors if they are reasonable and fulfil a purpose and add functionality to the project. It is quite common that you have a use-case the maintainer didn’t think of before, and that you’ve helped the project grow by contributing your code!\n\n\n9.2 Amending commits\nOnce in a while you’ll have just committed something to your Git repo and immediately remembered that you forgot to add something small, or perhaps you saw an error somewhere. While you can certainly just add that and make a new commit, wouldn’t it be nicer if you could just make the change as if it was already a part of the first commit? Well, you can! Just make the change, stage it and the commit together with the --amend flag, like so:\ngit add &lt;file&gt;\ngit commit --amend\nThis will add the staged changes to the previous commit as if they had always been there. Be careful, though! This will actually rewrite history, meaning that it only works if you only amended local changes. If you had already pushed the first commit to a remote repository you would run into trouble: you will be able to make the amend without issue, but you’ll get an error when you try to push your new changes, since the remote already contains the first version of the commit and can’t simply rewrite what it already has.\nAmending changes is thus a good way to fix small mistakes you realise you made just after committing them, as long as you only amend local changes!\n\n\n9.3 Rebasing\nThe git rebase command is an alternative to git merge in that it solves the same problem: getting changes in one branch into another branch. We’ve already gone through merging extensively, so how is rebasing different? Let’s look at a common case: a feature-branch which we want to get into the main branch.\n\nRecall that a merge creates a merge commit, something akin to Merge branch 'feature-branch' into main or similar. This is a new commit that didn’t exist that brings the changes on feature-branch into main, but it contains no actual work itself. This is both a good and a bad thing: good, because merging is a safe, non-destructive operation (it doesn’t alter history); bad, because it can make the history itself look quite messy. These are the commands used and what the history will look like afterwards:\ngit switch main\ngit merge feature-branch\n\n(The commit with the dashed border is the merge commit.)\nRebasing, on the other hand does not create merge commits. Indeed, what rebase does is to “re-base” one branch on the other, i.e. pretend that new changes were done on a different base than what actually happened (hence the name). Getting our feature-branch onto main using rebase actually entails two separate steps: first the rebase itself, followed by a fast-forward merge:\ngit switch feature-branch\ngit rebase main\n\nThis step rebases our feature-branch on top of main, meaning that we pretend that the commits on feature-branch were done based on the latest commits on main - you can also think of it as moving the entire feature-branch to the tip of the main branch. The commits with the dashed borders here indicate brand new commits; rebasing can’t somehow move the commits to the new base, rather it has to “replay” those commits as if they were done on the new base.\ngit switch main\ngit merge feature-branch\n\nWe’ve now got our feature-branch commits onto main with a single, linear history without any merge commits! We did have to rewrite history, though, when we did the rebase itself. As with amending (see above), this is fine if we’re only working locally, but we’ll quickly run into trouble if we try to rebase things that have already been pushed. We can rebase on top of remote things, of course, since we’re not changing any remote history, only the local history. Be careful when you rebase!\n\n\n9.4 Rebasing as clean-up\nIf the above section felt scary, don’t worry! There’s another highly useful use-case for git rebase that doesn’t risk destroying any history, namely local clean-up!\nLet’s imagine you’ve worked on your local feature-branch for some time, and you have a number of commits on it. Some are highly related to each other and might actually be better suited as a single commit. You’ve also spotted a spelling error in one commit message, and realised that you missed important information in another. We can actually solve all of these issues with an interactive rebase! If you have 4 commits on your branch you can type the following:\ngit rebase -i HEAD~4\nThe -i flag means interactive, while HEAD~4 means 4 commits back from HEAD. This will open your default text editor and give you a selection looking something like this:\npick 0abf162 First feature commit\npick befc682 A minor change on the first commit\npick c9d1426 A commit with an uncomplete commit message\npick 2e0cb97 A commit with a spelling mitake\n\n# Rebase 879ddcc..0abf162 onto 879ddcc (4 commands)\n#\n# Commands:\n# p, pick &lt;commit&gt; = use commit\n# r, reword &lt;commit&gt; = use commit, but edit the commit message\n# e, edit &lt;commit&gt; = use commit, but stop for amending\n# s, squash &lt;commit&gt; = use commit, but meld into previous commit\n\n(... more instructions ...)\nThe commits are ordered with the most recent one at the bottom. The commented instructions (all of which are not shown here) show you what alternatives you have to work with; all you have to do is to change the pick keyword next to the commit hashes to whatever keyword you need from the list, save and exit.\nIn order to solve the toy example here we might decide that the four keywords should be pick, squash, reword and reword, from top to bottom. Once that’s done simply save and exit, and another instance of your default text editor will open for you to complete the specified changes. In the case above we’d get two separate new instances where we can change the commit message - these work the same as any normal commit.\nInteractive rebasing is thus well-suited for fixing and cleaning of local changes you have yet to push anywhere, even if you don’t use rebasing as an alternative to merging! This can make your Git history both cleaner and more concise, which is great when you’re collaborating with others.\n\n\n9.5 Resetting\nSometimes you’ll want to simply discard changes you’ve already committed. This should, however, be something that you rarely have to do. Completely moving back to a previous commit is something called a hard reset, which can be accomplished like so:\ngit reset --hard 5b83463\nYou specify the commit you wish to return to, discarding all other changes, including any changes done to the working directory. It goes without saying that this command is among the most dangerous commands available in Git and should be used with caution.\n\n\n9.6 The reflog\nWe have shown many ways to work with Git and its various commands, and it occasionally happens that errors are introduced - especially when you’re not careful with using git commit --amend, git rebase or git reset on remote changes. This is where the reflog comes in. Think of the reflog as Git’s “safety net”: it stores almost every change you make to a Git repository (regardless of whether you commit the change) in a chronological manner. The following is an example of what the output of the git reflog command might show:\n58deba6 HEAD@{0}: merge: feature-branch: Fast-forward\n8c80c88 HEAD@{1}: checkout: moving from feature-branch to main\n555544a HEAD@{2}: commit: feature development 2\n4c92630 HEAD@{3}: commit: feature development 1\n8c80c88 HEAD@{4}: checkout: moving from main to feature-branch\nIt shows the most recent change at the top, notified by HEAD@{0}. We thus have a merging of feature-branch into main, a checkout (switch) into main, two commits on feature-branch and a checkout into feature-branch - reading it backwards we get a chronological log of what has happened.\nThe reflog is incredibly useful for when you’ve lost something you later realise you want to access again, such as when you’ve just used git reset. The reflog might look like this, for example:\nbc3641f HEAD@{0}: reset: moving to HEAD~2\ncaf9321 HEAD@{1}: commit: More work on the feature\n1bc36af HEAD@{2}: commit: Work on a new feature\nWe see two commits related to some new feature and a reset to HEAD~2 (two commits back from HEAD). If we realise that we actually liked the work we just threw away we can move around in the reflog in a similar manner we do normal commits:\ngit reset HEAD@{1}\nThis will put us back to the state we were in before we used git reset. We here refer to the reflog using the HEAD@{N} notation, which differs from the usual HEAD~N notation so that it is clear if it is the commit history or the reflog that is intended. While the reflog is hopefully not something you’ll have to use often it’s quite useful to know it exists, if only to be able to search the internet for more details regarding a problem you’ve encountered!\n\n\n9.7 Decorating your prompt\nWhen you are working on the command line interface (CLI), you will usually have some small pieces of information relating to your current directory, the name of the computer or host you’re working on, and so forth. You’ve probably already seen your prompt while working with Git throughout this lesson, but here’s an example of what one might look like:\nerikfmbp:~/teaching/workshop-reproducible-research erik.fasterius $\nThe above prompt contains the name of the computer, a colon, the current working directory, the username and a dollar-sign; it is stored in the variable PS1. You can type echo $PS1 to see what variables your prompt is made up of; the above example contains \\h:\\W \\u\\$, where \\h is the hostname, \\W the working directory and \\u the username.\n\n\n\n\n\n\nNote\n\n\n\nIf you’re using zsh instead of bash you’ll have to replace the backslashes (\\) in the commands with percent signs (%).\n\n\nSome people like to also show the current branch on their prompt, thus avoiding having to type git branch continuously. There are several ways you might do this, and we’re only presenting one of them here: a bash function.\ngit_branch() {\n     git branch 2&gt; /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/ (\\1)/'\n}\nThis function does a number of things:\n\nEjects the error message from Git if the current directory isn’t a part of a Git repository into /dev/null (i.e. into nothing).\nFind the current branch by searching for a line that starts with * (i.e. the current branch) using the command line program sed.\nPut the current branch into parentheses with a space before it.\n\nWe can then build our new prompt by adding this function into it:\n# The first part of the old prompt\nPS1='\\h:\\W \\u'\n\n# Add the Git branch\nPS1=$PS1'$(git_branch)'\n\n# Add the last part of the old prompt\nPS1=$PS1' \\$'\nNow you should see the current Git branch on your prompt! The only problem now is that this only works for your current session: once you restart your CLI you’ll have to re-define your prompt again. This can be circumvented, though. What you need to do is to add the code defining your prompt into your so-called bash profile: ~/.bash_profile. Every time you load a new CLI session this file is read and any code inside it is executed. You might already have this file, so make sure you don’t overwrite it!\n\n\n9.8 Bash aliases for git\nSome Git commands are used over and over again when working with git, such as git status. Some people like to have aliases (i.e. shortcuts) for these common commands. Here is a small list of such aliases that you may find useful or, even better, might inspire you to create your own! Add them to your ~/.bash_profile as above, so that they’re available across sessions.\n# Basic Git commands\nalias ga='git add'\nalias gb='git branch'\nalias gc='git commit'\nalias gd='git diff'\nalias gl='git log'\nalias gm='git merge'\nalias gp='git push'\nalias gt='git tag'\nalias gu='git pull'\nalias gw='git switch'\n\n# Git status in short format\nalias gs='git status --short'\n\n# Show diff of staged files\nalias gds='git diff --staged'\n\n# Add and commit all tracked and modified files\nalias gca='git commit --all'\n\n# Create and switch to a new branch\nalias gwc='git switch --create'\n\n# Git log with one line per commit\nalias glo='git log --oneline'\n\n\n9.9 Pretty logs\nIf you want to customise e.g. the format and the colours of the logs you can use the gitconfig file (the same one we added things to using git config --global user.name \"Mona Lisa\" in the pre-course setup). You can read more about exactly what you can do at the documentation for Git configs and pretty formats, but we’ll provide two examples here:\n[format]\n    pretty = format:%C(yellow)commit %H %C(auto)%d %nAuthor: %C(cyan)%aN %C(italic reset)(%ae) %nDate:   %C(blue)%ar %C(italic reset)(%ai) %n%n%C(bold reset)%w(0,6,6)%s%n%C(reset)%+b\nThis first example alters the format of the default git log command. It looks similar to what you’d be used to seeing with that command, except his has some colour highlights and adds the relative date (e.g. “1 hour ago” and similar relative times).\n[pretty]\n    line = format:%C(yellow)%h %C(blue)%&gt;(12)%ar %C(cyan)%aN%C(auto)%d %C(reset)%s\nThis second example is a custom format that can be called using git log --pretty=&lt;format-name&gt;, and is similar to the built-in --oneline flag, but also containing nicer colours, the relative date as well as the author name ;the format name line here is used for its similarity to oneline. You can add any number of custom formats you like using such config specifications. If you’re using aliases as in the section above you might change the glo alias to be git log --pretty=line instead, which will give you the nicer log on one line."
  },
  {
    "objectID": "pages/markdown.html",
    "href": "pages/markdown.html",
    "title": "Markdown",
    "section": "",
    "text": "A markup language is a system for annotating text documents in order to e.g. define formatting. HTML, if you are familiar with that, is an example of a markup language. HTML uses tags, such as:\n&lt;h1&gt; Heading &lt;/h1&gt;\n&lt;h2&gt; Sub-heading &lt;/h2&gt;\n&lt;a href=\"www.webpage.com\"&gt; Link &lt;/a&gt;\n&lt;ul&gt;\n  &lt;li&gt; List-item1 &lt;/li&gt;\n  &lt;li&gt; List-item2 &lt;/li&gt;\n  &lt;li&gt; List-item3 &lt;/li&gt;\n&lt;/ul&gt;\nMarkdown is a lightweight markup language which uses plain-text syntax in order to be as unobtrusive as possible, so that a human can easily read it. Look at the following toy example:\n# A header\n\nA [link](http://example.com).\n\n## A sub-header\n\nText attributes _italic_, *italic*, **bold**, `monospace`.\n\n### A deeper sub-header\n\nBullet list:\n\n  - Apples\n  - Oranges\n  - Pears\nThis would render to something like this:\n\nA markdown document can be converted to other formats, such as HTML or PDF, for viewing in a browser or a PDF reader; in fact, the page you are reading right now is written in markdown. Markdown is somewhat ill-defined, and as a consequence of that there exist many implementations and extensions. They share most of the syntax, however, with various additions on top.\nThere are a lot more things you can do with markdown than what we show here. Indeed, this entire course is mostly written in markdown! You can read more about markdown here."
  }
]